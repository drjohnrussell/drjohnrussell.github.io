[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "John Russell",
    "section": "",
    "text": "Hi there! I’m John Russell. In my work as a professor and education researcher, I love sensemaking in data, science and education, learning and implementing systems of professional learning, and the spaces that support the ways in which these pursuits support each other. Outside of work, I’m a kayaker, a lover of board games, and an explorer (mostly via my bicycle) of New York City, where I live. Please explore to learn more about me and my work!"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "John Russell",
    "section": "",
    "text": "Exploring a 3-D Synthetic Dataset\n\n\n\nR\n\n\n\nUsing plotly to visualize a three-dimensional dataset\n\n\n\nJohn Russell\n\n\nApr 12, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstructing the Hertzsprung-Russell Diagram\n\n\n\nR\n\n\nScience\n\n\n\nUsing ggExtras to help find the right margins for a famous plot\n\n\n\nJohn Russell\n\n\nMar 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWorking with Time to battle Baby Amnesia\n\n\n\nR\n\n\nData Wrangling\n\n\nTime\n\n\n\nDemonstrating how the tidyverse’s use of time can better help me remember my first son’s sleep schedule\n\n\n\nJohn Russell\n\n\nFeb 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing fuzzyjoin to work with NCES data\n\n\n\nR\n\n\nData Wrangling\n\n\n\nDemonstrating how fuzzyjoin can help you with messy data through an example using school names within the Virgin Islands\n\n\n\nJohn Russell\n\n\nJan 17, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing gganimate and ggflags to look at democratic progress\n\n\n\nQuarto\n\n\nR\n\n\nGeography\n\n\nTidy Tuesday\n\n\n\nUsing a TidyTuesday dataset to experiment with gif packages\n\n\n\nJohn Russell\n\n\nJan 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGetting back into blogging\n\n\n\nQuarto\n\n\nR\n\n\n\nUsing Quarto as an entrance back into blogging\n\n\n\nJohn Russell\n\n\nDec 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Diversity in Baseball\n\n\n\nR\n\n\nBaseball\n\n\n\nForming Word Clouds with an International Perspective\n\n\n\nJohn Russell\n\n\nMar 22, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA bipartite case (part 2)\n\n\n\nR\n\n\nSocial Network Analysis\n\n\n\nLooking at course enrollments from a teacher perspective\n\n\n\nJohn Russell\n\n\nMar 16, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy time at MƒA\n\n\n\nR\n\n\n\nGrowth over seven years\n\n\n\nJohn Russell\n\n\nFeb 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA bipartite case (part 1)\n\n\n\nR\n\n\nSocial Network Analysis\n\n\n\nLooking at course enrollments\n\n\n\nJohn Russell\n\n\nFeb 17, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2022-03-22-diversity-baseball/index.html",
    "href": "posts/2022-03-22-diversity-baseball/index.html",
    "title": "Understanding Diversity in Baseball",
    "section": "",
    "text": "Note - this post was done before my work at EL Education, where Quarto and R are utilized not just for analysis, but for communication as well. Future posts will center code blocks and be easier for others to work with."
  },
  {
    "objectID": "posts/2022-03-22-diversity-baseball/index.html#problem-how-do-we-demonstrate-the-growth-of-mlb-as-an-international-sport",
    "href": "posts/2022-03-22-diversity-baseball/index.html#problem-how-do-we-demonstrate-the-growth-of-mlb-as-an-international-sport",
    "title": "Understanding Diversity in Baseball",
    "section": "Problem: How do we demonstrate the growth of MLB as an international sport?",
    "text": "Problem: How do we demonstrate the growth of MLB as an international sport?\nI finished the truly excellent Analyzing Baseball Data with R, and wanted to think about the opportunities that the different databases afforded that perhaps were not covered in the book. One of those opportunities was in thinking about where MLB has moved as a sport that pulls players from across the world.\n\nData:\nSean Lahman is an investigate reporter and sabermatrician who keeps an open source database with complete batting and pitching statistics for the major leagues from 1871 through 2021. In R, you can access this database by installing the Lahman package.\nOne tiny issue you have to overcome, however, is that it keeps discrete databases of Batting statistics, Pitching statistics and a Master list (called Player). The Master list, which gives the country of birth, does not give which seasons a player played.\nIn addition, a bar graph which shows every single country that a player was born in will get more than a little bit messy. That graph is shown here.\n\n\n\nCountries\n\n\nIn the end, it would be nice to have a graphical representation of just the top countries, and to also think of a better visualization to show the greater diversity present in the game today.\n\nSolution\nThe issues above can be solved in a few different ways:\n\nUse rbind, left_join and distinct to pull together players from the Batting and Pitching databases, add their birth country, and then eliminate duplicates.\nCreate a ‘decade’ variable that lets you separate players into the decades that they played (allowing a player to show up multiple times across decades).\nTake advantage of group_by to count players in different countries, or to visualize players by their name.\nExperiment with slice to make column graphs with only the top 10 countries, and with the wordcloud package to visualize diversity through the names of the players themselves.\n\n\n\nGraphs, and Observations\nI started out being interested in the countries that players came from. Here are three graphs, showing the top 10 countries for foreign players in the 1930s, 1970s (which was only one decade after all teams were integrated), and the 2010s.\n\n\n\n1930sColumn\n\n\nWith 8 players representing Canada, it’s pretty easy to see that MLB was not drawing international players in the 1930s.\n\n\n\n1970sColumn\n\n\nThe influence of Latin American players is well underway by the 1970s, with Puerto Rico leading the way.\n\n\n\n2010sColumn\n\n\nThe y-axis definitely gives it away! It also made me want to understand the Cuban players in the 1930s, or how Venezuela became a pipeline for players (and it explains in part why so many play in the Venezuelan league in the off-season).\nReally, though, I wanted a better representation of this diversity; something that put names to the players. So I defined a diversity variable, loosely defined as the percentage of players with a given name who were born out of the country, and then created word clouds of most common names in baseball. What follows are those word clouds for the 1970s and 2010s.\n\n\n\n1970sMLB\n\n\nIn this word cloud, Jim and Mike are the most common names in baseball, with players named Jim and Bob being the most likely to be born within the United States.\n\n\n\n2010sMLB\n\n\nFor the 2010s, there is a greater diversity of names and a greater diversity of players born outside of the country. This word cloud (of the 400 most common names) allows one to see that diversity in a way that a column graph cannot do.\n\n\n\nWalking through the Code\nWe’ll be using graphs and wordclouds from the tidyverse and wordcloud package, and we’ll also load the Lahman package for our data. I like using RColorBrewer for palettes.\nlibrary(tidyverse)\nlibrary(Lahman)\nlibrary(RColorBrewer)\nlibrary(wordcloud)\nUsing rbind, mutate and left_join allows us to create a list of batters and pitchers, complete with their birth country, for each decade that the dataset allows.\nDecadeList &lt;- rbind(Batting[,c(\"playerID\",\"yearID\")],Pitching[,c(\"playerID\",\"yearID\")])\nDecadeList &lt;- DecadeList %&gt;% mutate(decade=10*floor(yearID/10))\nDecadeList &lt;- distinct(DecadeList,playerID,decade,.keep_all=TRUE)\nDecadeList &lt;- left_join(DecadeList[,c(\"playerID\",\"decade\")],People[,c(\"playerID\",\"birthCountry\",\"nameFirst\",\"nameLast\")],by=\"playerID\")\nDecadeList &lt;- drop_na(DecadeList)\nIn order to create our word cloud, we will need a new variable, which will let us know whether someone was born in the United States, or not. From this variable, we can group the dataset by first name and decade, and then find the average of everyone in those groups.\nDecadeList &lt;- mutate(DecadeList,homegrown=as.integer(birthCountry==\"USA\"))\nMeans &lt;- DecadeList %&gt;% group_by(nameFirst,decade) %&gt;% summarize(Average=mean(homegrown))\nDecadeList &lt;- left_join(DecadeList,Means,by=c(\"nameFirst\",\"decade\"))\nNow we have everything for our column graphs! Using dplyr, we can group the data by country, find a count, and then ungroup them to graph. Code below only for 1970, but this could be done for any decade.\nDecade1970 &lt;- DecadeList[DecadeList$decade==1970&DecadeList$birthCountry!=\"USA\",]\nDecade1970USA &lt;- DecadeList[DecadeList$decade==1970,]\nDecade1970 %&gt;% group_by(birthCountry) %&gt;% count(sort = TRUE) %&gt;% ungroup() %&gt;% slice(1:10) %&gt;% ggplot(aes(x=birthCountry,y=n))+geom_col()+theme_minimal()+theme(legend.position=\"none\", axis.title.x=element_blank(),plot.title=element_text(hjust = 0.5))+labs(title=\"Top 10 countries for foreign players in MLB, 1970s\",y=\"Number of players\")\nCreating the word cloud requires us to bring back the Means database, and to find a way to shorten the database to just the names in a decade, the number of people with that name, and the percentage of those people born in the United States. By ordering the data, we can be sure that they are colored correctly in the cloud as well.\nDecade1970count &lt;- Decade1970USA %&gt;% group_by(nameFirst) %&gt;% count()\nMeans1970 &lt;- Means[Means$decade==1970,]\nDecade1970count &lt;- left_join(Decade1970count,Means1970,by=\"nameFirst\")\nDecade1970count &lt;- Decade1970count[order(Decade1970count$Average),]\ncolor_range_number &lt;- length(unique(Decade1970count$Average))\nwordcloud(Decade1970count$nameFirst,Decade1970count$n,max.words=300,random.order=FALSE,ordered.colors=TRUE, colors=colorRampPalette(brewer.pal(6,\"RdBu\"))(color_range_number)[factor(Decade1970count$Average)])\nAnd there you have it! A note - wordclouds are not like other graphs that you create, in that they are straight image files. This means that, to give them a title and a legend, it’s easiest just to import them into an image editor (I use Inkscape) and deal with it there.\n\nTo learn more\nThe following links helped me think through this problem. In particular, figuring out how to create a word cloud that was colored by another variable was a tricky problem to figure out:\n\nStack Overflow Post on Wordclouds\nA tutorial I used when first learning wordcloud by Céline Van den Rul"
  },
  {
    "objectID": "posts/2022-02-28-time-at-mfa/index.html",
    "href": "posts/2022-02-28-time-at-mfa/index.html",
    "title": "My time at MƒA",
    "section": "",
    "text": "Note - this post was done before my work at EL Education, where Quarto and R are utilized not just for analysis, but for communication as well. Future posts will center code blocks and be easier for others to work with."
  },
  {
    "objectID": "posts/2022-02-28-time-at-mfa/index.html#my-time-at-mƒa",
    "href": "posts/2022-02-28-time-at-mfa/index.html#my-time-at-mƒa",
    "title": "My time at MƒA",
    "section": "My time at MƒA",
    "text": "My time at MƒA\nAs it will be announced in the next week, due to a desire for research to be an external and not internal initiative at MƒA , it is the desire of the board and leadership to cut my department, meaning I will be leaving the organization in the coming months, thankfully with the support of my directors in the job search.\nI have grown each of the programs I have been a part of, and while it is time to look for opportunities to grow elsewhere, I also wanted to use this place to reflect on the impact that I have been able to have in my seven years here, and the impact it has had on me.\nBecause this is a data and R programming blog, however, let me break each section into one chart.\n\nProgram Officer for Professional Development\n\n\n\nPDTeam\n\n\nWhile I was doing some part-time and summer work, this was my first full-time job out of the classroom. In fact, leaving the classroom was so hard that I volunteered to do an elective at my school in my first year, just so that I could still see my students.\nI was the first Program Officer for science, and in some ways, it showed. Many of the content courses at MƒA were given by postdocs with very little teaching experience, and in particular, ideas around how to form effective professional learning communities where teachers of the same content could learn from each other were incredibly naïve.\nIn my time as a Program Officer, and with the help of incredible colleagues, we increased the quality and the quantity (graphed above) of courses offered. We started programs like Scopes for Schools, where amateur astronomers would come to schools on Family Science nights with telescopes. We were able to better sustain partnerships that already existed, and form new ones with government organizations such as the NYS Department of Environmental Conversation and university programs such as Columbia University’s Frontiers of Science. Registration day each semester came with such joy, as teachers logged on at exactly 4 PM and chose the courses that you had set up.\nI also worked on my dissertation, on the supports teacher leaders require to effectively lead professional learning communities, which aided in the creation of multiple tools, many of which are now featured on MƒA’s Teaching and Learning Resources.\n\n\nResearch Associate\n\n\n\nAIMTRU\n\n\nAfter three years as a Program Officer, I spent the final year of my dissertation as a Research Associate. In this position, I worked to advocate for models of teacher leadership by supporting initiatives within and outside of New York City. In particular, I helped with the formation and successful evaluation of the NJ STEM Innovation Fellowship, and with piloting a professional learning model centered on high quality instructional materials that was awarded an NSF DRK-12 grant.\nThe success of each of these initiatives was no small feat; our evaluator on NJ STEM actually passed away in the middle of the first year of the fellowship, and I took over their work on top of my own. NSF grants are rarely given to people on their first application, and it was in large part due to the data we were able to provide on its early success that convinced them this was worthwhile. The chart above, from the first year after we received the grant, shows pre/post testing on the knowledge that teachers had of the high quality instructional materials that were at the center of the model (Formative Assessment Lessons, or FALs) as well as the framework for powerful teaching that they were based on (the Teaching for Robust Understanding framework, or TRU).\nWhile building the course catalog as a program officer was a collaborative process with the rest of the team, the work on these initiatives as an associate felt like true partnerships, where we each brought our expertise to bear, and I learned a lot about my strengths as a design-based researcher translating ideas to products, and the things I needed to work on to make sure that everyone felt supported in these processes.\n\n\nSenior Education Researcher\n\n\n\nEVu29wuXQAIr1IU\n\n\nBuilding on the success of these initiatives, I was promoted to a senior researcher, able to be a part in the design, implementation, and evaluation of entire programs of research. I have been able to return to my dissertation in some ways, extending the TRU framework from classroom practice to the professional learning sphere in order to support PD leaders. I have also taken to the tools of social network analysis, understanding how we can think of communities of practice as places where knowledge flows. Hopefully, I’ll be able to use some of this space to talk more about this work in the near future.\nIt has been a pleasure to be a part of MƒA. My skills in professional development, research, and analyzing data have grown over my time here, in large part because I was provided so many opportunities to try something out and to learn from the process; it’s something that I won’t take for granted, wherever I end up.\n\n\nWalking through the Code\nFor the first graph, I take advantage of gganimate and gifski, which allows you to render gifs easily in the R space. I’m also doing some piping and color work, so I’ll be loading dplyr, tidyverse, and RColorBrewer.\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(gganimate)\nlibrary(gifski)\nlibrary(RColorBrewer)\nlibrary(dplyr)\nUnfortunately, the data, as it was downloaded from Salesforce, used Winter/Spring as opposed to Spring, which is far too much text for a graph. After loading my dataset, I ran a recode on the Semester variable, and then factored so that the order was correct.\nCourses &lt;- Courses %&gt;% mutate(Semester = recode(Semester, \"Winter/Spring 2013\" = \"Spring 2013\", \"Winter/Spring 2014\" = \"Spring 2014\", \"Winter/Spring 2015\" = \"Spring 2015\", \"Winter/Spring 2016\" = \"Spring 2016\", \"Winter/Spring 2017\" = \"Spring 2017\", \"Winter/Spring 2018\" = \"Spring 2018\", \"Winter/Spring 2019\" = \"Spring 2019\"))\nCourses$Semester &lt;- factor(Courses$Semester, levels = c(\"Fall 2012\", \"Spring 2013\", \"Fall 2013\", \"Spring 2014\", \"Fall 2014\", \"Spring 2015\", \"Fall 2015\", \"Spring 2016\", \"Fall 2016\", \"Spring 2017\", \"Fall 2017\", \"Spring 2018\", \"Fall 2018\", \"Spring 2019\", \"Fall 2019\"))\nAfter this, it’s just a matter of setting up the graph highlighting the semesters I was there using fill and then using transition_states to slow down the gif created using animate.\np &lt;- ggplot(Courses,aes(x=Semester,fill= ifelse((Semester== \"Fall 2015\" | Semester== \"Spring 2016\" | Semester== \"Fall 2016\" | Semester== \"Spring 2017\" | Semester== \"Fall 2017\" | Semester== \"Spring 2018\"), \"Highlighted\", \"Normal\")))\np &lt;- p +geom_bar()+scale_x_discrete(labels=label_wrap(6))+theme_minimal()+theme(legend.position=\"none\", plot.title=element_text(size=16, hjust=.5), axis.title.x=element_blank(), axis.title.y=element_blank())+labs(title=\"My time as a Program Officer at MƒA\", subtitle=\"Courses for Credit in the Catalog\")+transition_states(Semester, wrap=FALSE, transition_length=2)+shadow_mark()\nanimate(p, renderer = gifski_renderer(loop=TRUE))\nAn excellent introduction to gganimate can be found here.\nFor the second plot, using the data from AIMTRU, the biggest changes from your standard plot were using RColorBrewer library and the scale_fill_brewer function to set the palette to red-yellow-green, and facet_grid to separate the plots by the Test variable (indicating Pre/Post) as well as the Question variable. Factoring is again used to make sure that the levels are correct.\nAIMTRU$Answer &lt;- factor(AIMTRU$Answer, levels = c(\"5\",\"4\",\"3\",\"2\",\"1\"))\nAIMTRU$Question &lt;- factor(AIMTRU$Question, levels = c(\"Knowledge of FAL\",\"Knowledge of TRU\"))\nAIMTRU$Test &lt;- factor(AIMTRU$Test, levels = c(\"Pre\",\"Post\"))\np &lt;- ggplot(AIMTRU, aes(x=Answer, fill=Answer))\np + geom_bar() + scale_x_discrete(drop=FALSE) +theme_test()+scale_fill_brewer(palette = \"RdYlGn\")+theme(legend.position=\"none\", axis.title.x=element_blank(), axis.title.y=element_blank())+facet_grid(Question ~ Test)+labs(title=\"Pre/post testing from first year evaluation of AIM-TRU initiative\")\nFor the third plot, I refer you to this posting I did last week, which goes into far more detail into how matrix algebra is used to tease apart bipartite data in order to make it more network-friendly."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "John Russell",
    "section": "",
    "text": "Bluesky\n  \n  \n    \n     LinkedIn\n  \n  \n    \n     Github\n  \n\n  \n  \n\n\nTeachers College at Columbia University | New York, NY\nEdD in Science Education | May 2018\nPace College | New York, NY\nMA in Education | June 2007\nWashington University in St. Louis | St. Louis, MO\nBS in Earth & Planetary Sciences (minor: Physics) | May 2014\n\n\n\nEL Education | Director of Internal Research\nJuly 2022 - present\nMath for America | Program Officer, Education Researcher\nAugust 2015 - July 2022\nNYC Public Schools | Science Teacher\nSept 2005 - August 2015"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "John Russell",
    "section": "",
    "text": "Teachers College at Columbia University | New York, NY\nEdD in Science Education | May 2018\nPace College | New York, NY\nMA in Education | June 2007\nWashington University in St. Louis | St. Louis, MO\nBS in Earth & Planetary Sciences (minor: Physics) | May 2014"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "John Russell",
    "section": "",
    "text": "EL Education | Director of Internal Research\nJuly 2022 - present\nMath for America | Program Officer, Education Researcher\nAugust 2015 - July 2022\nNYC Public Schools | Science Teacher\nSept 2005 - August 2015"
  },
  {
    "objectID": "about.html#my-journey-from-classroom-to-research",
    "href": "about.html#my-journey-from-classroom-to-research",
    "title": "John Russell",
    "section": "My Journey from Classroom to Research",
    "text": "My Journey from Classroom to Research\n\n\nI am a scientist by training; I worked in seismology and geochemistry labs through college, majored in Earth and Planetary Sciences, and even in my later years as a teacher, I would take coursework in the evening on sedimentary geology and spend summers working in a climate lab to keep my skills fresh. I was always drawn to the geosciences, in large part for the ways in which they sought to make sense of the world around us, and in particular the ways in which it could be done with a quantitative bent. In spite of pursuing a doctorate in education, my elective courses were entirely in upper level geochemistry and statistics.\n\n\n\n\n\n\n\nPhoto with outcrop for Sedimentary Geology course\n\n\n\n\n\n\n\nI have taught for nearly the entirety of my pre-teen and adult life, as a swimming instructor in high school, a tutor of students with autism in college, and during my gap year, I struggled to convince myself that science was my calling. In the end, I applied for and became a Teach for America teacher, being placed in the South Bronx. A two year commitment became a ten year calling; I helped found a middle school in Harlem, where I taught Regents Earth Science to 8th graders and was certified to teach a College Geology class to upperclassmen. During this time, I started to dabble in expanding my impact outside of the classroom by designing and facilitating professional development, which became my next calling.\n\n\n\n\n\n\n\nReceiving American Geoscience Institute’s award for excellence in Earth Science Education.\n\n\n\n\n\n\n\nI left the classroom as an organization’s first Program Officer for Science Education, responsible for building partnerships and designing opportunities for over one thousand public school STEM teachers in NYC. In order to meet the needs for a diverse community, it was also at this point that I started leveraging data science, the Salesforce infrastructure that we were working in, and surveys to best tailor the catalog to the audience that existed. I finished my doctorate at Teachers College, and applied that by starting the organization’s first Research Department, where we won our first research grant (a DRK-12 grant on the intersection of curricular materials, video cases and professional development in mathematics). I loved the opportunity to build from scratch, and to also start working within R.\n\n\n\n\n\n\n\nThe course catalog at the organization immediately increased upon my hire.\n\n\n\n\n\n\n\nI was really fortunate to be given a long runway at Math for America when they decided to find external evaluators to continue the work I had started, and I used that time to look into a few organizations before ending up at EL Education, a nonprofit that takes a full school approach to student achievement reflective of their founding as a collaboration between Outward Bound and Harvard Graduate School of Education. Here, I do work in internal program evaluation and in improvement science, helping provide informal and formal data tools (measurement and analysis) that align with our mission. It is also here that my work in R has flourished, a big reason I wanted to start this blog up again."
  },
  {
    "objectID": "posts/2022-02-17-bipartite-case-i/index.html",
    "href": "posts/2022-02-17-bipartite-case-i/index.html",
    "title": "A bipartite case (part 1)",
    "section": "",
    "text": "Note - this post was done before my work at EL Education, where Quarto and R are utilized not just for analysis, but for communication as well. Future posts will center code blocks and be easier for others to work with."
  },
  {
    "objectID": "posts/2022-02-17-bipartite-case-i/index.html#problem-do-stem-teachers-across-disciplines-within-a-fellowship-program-get-the-opportunity-to-meet-through-the-courses-they-take",
    "href": "posts/2022-02-17-bipartite-case-i/index.html#problem-do-stem-teachers-across-disciplines-within-a-fellowship-program-get-the-opportunity-to-meet-through-the-courses-they-take",
    "title": "A bipartite case (part 1)",
    "section": "Problem: Do STEM teachers across disciplines within a fellowship program get the opportunity to meet through the courses they take?",
    "text": "Problem: Do STEM teachers across disciplines within a fellowship program get the opportunity to meet through the courses they take?\nThis problem is incredibly important for the organization, as a part of their mission is to build a community of practice among their teachers. If science teachers and mathematics teachers don’t have a way to interact, then there isn’t a way for information to flow among the community through the courses they are in together.\n\nData:\nThe data provided to explore this problem was course enrollment data, specifically looking at the enrollment within courses with multiple workshops over the course of a semester.\n\n\nSolution\nCourse enrollment data are what is known as bipartite data - that is, the data can be divided into two independent sets. It is typically graphed as a bipartite graph.\nLet’s use the following sample table and its associated graph\n\n\n\nGroup 1\nGroup 2\n\n\n\n\nX\nA\n\n\nX\nB\n\n\nX\nC\n\n\nX\nE\n\n\nY\nA\n\n\nY\nB\n\n\nY\nD\n\n\nY\nE\n\n\nZ\nB\n\n\nZ\nD\n\n\nZ\nE\n\n\n\n\n\n\nbipartitegraph\n\n\nWhile this type of graph is useful at a glance to notice connections, what we are interested in is co-enrollments; that is, who is in a course with whom, and in particular, whether there are courses that act as bridges among mathematics and science teachers.\nWe can do this with a little bit of matrix algebra. If you multiply an incidence matrix by its transpose, then you convert a two-mode matrix into a one mode incidence matrix. R is particularly suitable for converting incidence matrices into an igraph object, which you can plot and even pull interesting centrality measures from.\nIn matrix multiplication, order matters! Depending upon whether you multiply the transpose first or second, you would get the following adjacency matrices.\n\n\n\n\nX\nY\nZ\n\n\n\n\nX\n0\n3\n2\n\n\nY\n3\n0\n3\n\n\nZ\n2\n3\n0\n\n\n\nin one form, or alternatively,\n\n\n\n\nA\nB\nC\nD\nE\n\n\n\n\nA\n0\n2\n1\n1\n2\n\n\nB\n2\n0\n1\n2\n3\n\n\nC\n1\n1\n0\n0\n1\n\n\nD\n1\n2\n0\n0\n2\n\n\nE\n2\n3\n1\n2\n0\n\n\n\nThese matrices tell you how many shared destinations there are. For instance, A and C share one common destination (X).\nFor our course enrollment data, this is perfect; we can now create a matrix and plot igraph objects in two different perspectives:\n\nA graph of teachers where every edge represents courses that they took together\nA graph of courses where every edge represents teachers that were co-enrolled in these courses\n\nFor this particular post, let’s look at the graph of courses.\n\n\nGraph, and Observations\nWithin the fellowship program, courses are generally organized by two principles:\n\nContent (Math, Science, CS, and Inquiry)\nType (Professional Learning Teams, Mini-Courses and Extended Length Courses)\n\nYou can see some really interesting things that come up in the graph, done using the igraph package and the Fruchterman-Reingold layout, which attempts to organize the data with greater centrality nodes at the center:\n\n\n\nGraphofTeachers\n\n\nThere are a few things that I noticed in this graph:\n\nThe “Inquiry, Practice and Leadership” and CS courses serve as a sort of mixing ground; that is, they have people in them who are co-enrolled in mathematics and science courses. They seem to be a necessary part of a course catalog that encourages mingling, and it would be interesting to look at the comparative audiences.\nMini-Courses are more central than Professional Learning Teams. This makes sense; they usually enroll more teachers, so there are more opportunities for co-enrollments with other classes. However, they seem to serve magnified importance in allowing teachers to see others.\nA fun next step would be to use R’s sna package in order to find the betweenness of the Nodes. Betweenness is a measure of how well a node acts as a bridge between neighborhoods, and it would be interesting to see which courses act as the bridges on the graph between pure mathematics and pure science courses.\n\nAs you can see, this method allows you to take something that is not naturally a network graph (bipartite data) and start to think about it using a network mindset.\nThis is enough to start to answer the question above. We’ll use the space below to walk through the code so you can do something similar with bipartite data that you have!\n\n\nWalking through the Code\nWe’ll be using graphs from the tidyverse package, as well as Matrix in order to allow matrix multiplication.\nlibrary(igraph)\nlibrary(ggraph)\nlibrary(Matrix)\nYou’ll need to load up three different data sets:\n\nYour main dataset. For the code below, we will call this Data\nA dataset that has extra information about your first column of interest A, which we’ll call NodeA\nA data set that has extra information about your second columd of interest B, which we’ll call NodeB\n\nThe next thing you’ll need to do is convert Data into an incidence matrix, which means that every enrollment will become a 1 at the intersection of the rows (which will be column A) and columns (which will be column B).\nIncidence &lt;-spMatrix(nrow=length(unique(Data$A)),\nncol=length(unique(Data$B)),\ni=as.numeric(factor(Data$A)),\nj=as.numeric(factor(Data$B)),x=rep(1,length(as.numeric(Data$A))))\nThe incidence matrix is now ready to be converted into an adjacency matrix. Depending upon whether you are interested in the first column or second column, it will define the order in which you do the matrix multiplication. In this case, we are interested in the adjacency matrix for the first column. Note that we signify the multiplication using %*%\nAdjacencyA &lt;- Incidence %*% t(Incidence)\nNow we can create an igraph object. However, we will then decompose it to an edge list, so that we can recreate the igraph object, adding back in the weights and involving the background data for the nodes that we wish. If you just wish to graph this with no information on the nodes, you can skip a few steps here. I’m naming my igraph object teachers.\nedgeA &lt;- graph.adjacency(AdjacencyA, mode=\"undirected\", weighted=TRUE, diag=FALSE)\n##this is where you lose weight\nedgeA2 &lt;- as_data_frame(get.edgelist(edgeA))\n##need to get it back and form the new igraph object with my nodes\nteachers &lt;- graph_from_data_frame(edgeA2, vertices=nodesA, directed=FALSE)\nteachers &lt;- set_edge_attr(teachers, \"weight\", value=E(edgeA)$weight)\nNow you have an igraph object ready to graph. In the graph above, V(teachers)$shape was defined by the type of course, and V(teachers)$color was set to the content of the course. E(teachers)$weight was also multiplied, so that larger co-enrollments stuck out.\n\nTo learn more\nThe following links helped me think through this problem:\n\nNetwork Visualization in R by Katya Ognyanova\nWorking with Bipartite/Affiliation Network Data in R by Sol Messing"
  },
  {
    "objectID": "posts/2022-03-16-bipartite-case-ii/index.html",
    "href": "posts/2022-03-16-bipartite-case-ii/index.html",
    "title": "A bipartite case (part 2)",
    "section": "",
    "text": "Note - this post was done before my work at EL Education, where Quarto and R are utilized not just for analysis, but for communication as well. Future posts will center code blocks and be easier for others to work with."
  },
  {
    "objectID": "posts/2022-03-16-bipartite-case-ii/index.html#problem-do-stem-teachers-across-disciplines-within-a-fellowship-program-get-the-opportunity-to-meet-through-the-courses-they-take-part-2",
    "href": "posts/2022-03-16-bipartite-case-ii/index.html#problem-do-stem-teachers-across-disciplines-within-a-fellowship-program-get-the-opportunity-to-meet-through-the-courses-they-take-part-2",
    "title": "A bipartite case (part 2)",
    "section": "Problem: Do STEM teachers across disciplines within a fellowship program get the opportunity to meet through the courses they take? (Part 2)",
    "text": "Problem: Do STEM teachers across disciplines within a fellowship program get the opportunity to meet through the courses they take? (Part 2)\n\nData:\nThe data provided to explore this problem was course enrollment data, specifically looking at the enrollment within courses with multiple workshops over the course of a semester.\n\n\nSolution and Code\nI walked through the Solution to this problem a month ago, but I wanted to return to it because it looked at this from a course perspective, instead of from a teacher perspective.\nIn order to set up R to create the adjacency matrix for a one-mode projection of the second column of bipartite data, you would just multiply by the transpose first:\nAdjacencyB &lt;- t(Incidence) %*% Incidence\nEverything else is the same as in the first posting. I also don’t like that triangle is not a shape that you can define for your nodes (circle and square are), so I ended up finding a function that creates triangle as an option in your plots. Code for that below:\nmytriangle &lt;- function(coords, v=NULL, params) {\n  vertex.color &lt;- params(\"vertex\", \"color\")\n  if (length(vertex.color) != 1 && !is.null(v)) {\n    vertex.color &lt;- vertex.color[v]\n  }\n  vertex.size &lt;- 1/200 * params(\"vertex\", \"size\")\n  if (length(vertex.size) != 1 && !is.null(v)) {\n    vertex.size &lt;- vertex.size[v]\n  }\n\n  symbols(x=coords[,1], y=coords[,2], bg=vertex.color,\n          stars=cbind(vertex.size, vertex.size, vertex.size),\n          add=TRUE, inches=FALSE)\n}\nadd_shape(\"triangle\", clip=shapes(\"circle\")$clip,\n                 plot=mytriangle)\n\n\nGraphs, and Observations\nTeachers can generally be organized in two buckets:\n\nWhat they teach\nWhere they teach\n\nThere are other parts of their identities that you could graph, but for those, I’d rather use common measures of homophily that are in the netseg package to see if there is anything out of the ordinary.\nFinally, I chose to omit edges with a weight of one by defining their color as NA. That is, each edge in these graphs represents a time that a teacher saw another teacher in multiple courses, giving them a greater change of having a meaningful meeting with each other.\nIn the first graph, content is the lens through which I created my plot.\n\n\n\nTeachersByContent\n\n\nWhile the courses graphs from the first posting show that there are places where teachers of differing content get a chance to meet each other, this graph shows that, for the most part, the greater majority of teachers see other teachers who teach the same content that they do.\nAll things considered, this is a simple fact of life - teachers choose courses that help them teach the content that they teach - so of course they see other teachers of the same content who make, for the most part, the same decision.\nA different perspective comes up when you fold in borough.\n\n\n\nTeachersByBorough\n\n\nWhile teachers are taking courses for the most part with teachers who teach the same content as them, they are seeing a diversity of the schools that they come from. This is a greater argument for the power of a community - that great ideas can diffuse across the city of New York.\n\n\nTo learn more\nThe following links helped me think through this problem:\n\nNetwork Visualization in R by Katya Ognyanova\nWorking with Bipartite/Affiliation Network Data in R by Sol Messing\nCreating a triangle for network graphs, borrowed from the FELLA package"
  },
  {
    "objectID": "posts/2024-12-28-getting-back-online/index.html",
    "href": "posts/2024-12-28-getting-back-online/index.html",
    "title": "Getting back into blogging",
    "section": "",
    "text": "In one of my last posts 2 years ago, I mentioned that I would be looking for work and leaving MƒA. I ended up doubling down on my research background and becoming a part of EL Education’s Research Team, where I have taken an improvement science perspective on the many different programs that they offer schools and districts in line with their vision for a more full definition of student achievement where you don’t measure a student merely on test scores, but on the measure of their work and their character."
  },
  {
    "objectID": "posts/2024-12-28-getting-back-online/index.html#time-since-mƒa",
    "href": "posts/2024-12-28-getting-back-online/index.html#time-since-mƒa",
    "title": "Getting back into blogging",
    "section": "",
    "text": "In one of my last posts 2 years ago, I mentioned that I would be looking for work and leaving MƒA. I ended up doubling down on my research background and becoming a part of EL Education’s Research Team, where I have taken an improvement science perspective on the many different programs that they offer schools and districts in line with their vision for a more full definition of student achievement where you don’t measure a student merely on test scores, but on the measure of their work and their character."
  },
  {
    "objectID": "posts/2024-12-28-getting-back-online/index.html#my-work-at-el-education",
    "href": "posts/2024-12-28-getting-back-online/index.html#my-work-at-el-education",
    "title": "Getting back into blogging",
    "section": "My work at EL Education",
    "text": "My work at EL Education\nMuch of that work has been about positioning EL Education around a data infrastructure that allows them to understand their partners and the impact of their work. This has involved projects that mirror many parts of the data science cycle:\n\n\n\nR For Data Science Cycle (Wickham & Grolemund)\n\n\n\nImporting Data from disparate sources, including federal databases such as NCES, state systems that hold accountability data, our own data within Salesforce, and the data our partners hold\nTidying Data, which involves not only making the data more rectangular, but also making sure that there is a common language of identifiers such that the data can be easily merged and used as filters for each other through inclusive and filtering joins\nAnalyzing the Data, which involves everything from the design of additional instruments to give a qualitative bent to the quantitative data, doing explanatory work to see how different subgroups of students and schools compare, doing modeling work to see how those comparisons relate to each other, and further to understand the story we wish to tell\nCommunication, which has involved dashboards, paramaterized reports, presentations, and other forms of data visualization. This work has gotten extensive enough to merit creating an EL Education Data Visualization guide to make sure that everyone doing this work is on the same page.\n\nThis work has been completely done in R and a combination of R Markdown (before) and Quarto (now). My expertise has grown, which has merited taking a look at my old blog, which was done primarily in Markdown, and redoing it in Quarto. This way, I can house the code for the work I’m doing and the explanation within one document, as I do in my work at EL Education.\nI hope to use this blog to talk through and showcase some of that work."
  },
  {
    "objectID": "posts/2024-01-13-gganimate-ggflag/index.html",
    "href": "posts/2024-01-13-gganimate-ggflag/index.html",
    "title": "Using gganimate and ggflags to look at democratic progress",
    "section": "",
    "text": "One of my New Year’s resolutions was to become less of a lurker and more of a doer within the Tidy Tuesday community. There had been one dataset that I was super interested in exploring, based on Democracy and Dictatorship. Loaded the dataset and a few packages.\n\n\nCode in R\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\nlibrary(countrycode) #this package looks up ISO codes, which can be useful\nlibrary(ggflags) #pulls flags\nlibrary(gganimate) #animations\n\ndat &lt;- tidytuesdayR::tt_load(2024, week = 45)\ndemocracy &lt;- dat$democracy_data\n\nhead(democracy)\n\n\n# A tibble: 6 × 43\n  country_name country_code  year regime_category_index regime_category   \n  &lt;chr&gt;        &lt;chr&gt;        &lt;dbl&gt;                 &lt;dbl&gt; &lt;chr&gt;             \n1 Afghanistan  AFG           1950                     5 Royal dictatorship\n2 Afghanistan  AFG           1951                     5 Royal dictatorship\n3 Afghanistan  AFG           1952                     5 Royal dictatorship\n4 Afghanistan  AFG           1953                     5 Royal dictatorship\n5 Afghanistan  AFG           1954                     5 Royal dictatorship\n6 Afghanistan  AFG           1955                     5 Royal dictatorship\n# ℹ 38 more variables: is_monarchy &lt;lgl&gt;, is_commonwealth &lt;lgl&gt;,\n#   monarch_name &lt;chr&gt;, monarch_accession_year &lt;dbl&gt;, monarch_birthyear &lt;dbl&gt;,\n#   is_female_monarch &lt;lgl&gt;, is_democracy &lt;lgl&gt;, is_presidential &lt;lgl&gt;,\n#   president_name &lt;chr&gt;, president_accesion_year &lt;dbl&gt;,\n#   president_birthyear &lt;dbl&gt;, is_interim_phase &lt;lgl&gt;,\n#   is_female_president &lt;lgl&gt;, is_colony &lt;lgl&gt;, colony_of &lt;chr&gt;,\n#   colony_administrated_by &lt;chr&gt;, is_communist &lt;lgl&gt;, …\n\n\nThis dataset shows, for every year from 1950 to 2000, classifications for countries around the world. In the spirit of January 6th, I chose to focus on whether countries have free and fair elections, here shown as has_free_and_fair_election.\nIn the interest of this exploration, I’m not interested in colonies, which are shown as NA in the regime_category_index.\n\n\nCode in R\ndemocracy &lt;- democracy |&gt; \n  ## removing colonies as much as possible to get down to countries\n  filter(!is.na(regime_category_index),\n         ## British Virgin Islands oddly keeps showing up in spite of status as colony\n         country_code!=\"VGB\") \n\n\n\n\nMy first inclination in the dataset was to take out the countries that only had free and fair elections or a lack thereof, in order to understand places that had democratic progress and democratic backsliding. This required setting up a filter for this work. tabyl from the janitor package is well set up for this, as it will quickly come up with cross counts.\n\n\nCode in R\ndemocracyfilter &lt;- democracy |&gt; \n  janitor::tabyl(country_name,has_free_and_fair_election) |&gt; \n  filter(`TRUE` &gt; 0 & `FALSE` &gt; 0)\n\n\nThis gives a nice filter for this work. In order to use the ggflags package, you need for the countries to be spelled out in iso2c format. Fortunately, the amazing countrycodes package will do that for you, and in addition, it can provide the continent for you as well, for additional explorations.\n\n\nCode in R\ndemocraticchanges &lt;- democracy |&gt; \n  inner_join(democracyfilter) |&gt; \n  mutate(iso2=countrycode(country_name,\"country.name\",\"iso2c\"),\n         continent = countrycode(iso2, \"iso2c\", \"continent\")) |&gt; \n  arrange(continent,`FALSE`) |&gt; \n         mutate(country_name=fct_inorder(country_name))\n\n\nNow we are ready to plot this with the help of the ggflags package. Let’s look at Europe and Africa, two continents associated with democratic progress and backsliding.\nThere is one big issue - we would like for this to show up as continuous bars, which your typical geoms will not do. However, we can think of the bars as parts of a rectangle, that extend from the beginning to end of each year. If we factor the countries, we can then plot them and rename the y axis at the end.\n\n\nCode in R\n## Let's create the y-labels for later on\ny_lab &lt;- democraticchanges |&gt; \n  distinct(country_name,iso2,continent)  |&gt; \n  mutate(y_mid = as.numeric(country_name),\n         name=country_name)\n## For Africa\nAfrica &lt;- democraticchanges |&gt; \n  filter(continent==\"Africa\") |&gt; \n  ggplot(aes(xmin=year, #left boundary of the rectangle\n             xmax=year+1, #right boundary of the rectangle\n             ymin=as.numeric(country_name)-.3, #lower boundary of the rectangle\n             ymax=as.numeric(country_name)+.3, #upper boundary of the rectangle\n             fill=has_free_and_fair_election)) +\n  geom_rect() +\n  # now let's plot flags between the rectangles and the y axis\n  ggflags::geom_flag(data=y_lab |&gt; \n                       filter(continent==\"Africa\"),\n                     mapping=aes(y=y_mid,\n                                 country=tolower(iso2), #ggflags needs lowercase iso2 to work\n                                 x=1945),\n                     inherit.aes=FALSE) + #we want this to be individual to this layer\n                     #now to rename the y axis\n  scale_y_continuous(breaks=y_lab$y_mid,labels=y_lab$country_name) +\n  theme_minimal() +\n  theme(legend.position=\"bottom\",\n        legend.text=element_text(size=7),\n        legend.title=element_text(size=7)) +\n  labs(x=\"\",\n       y=\"\",\n       fill=\"Has Free and Fair Elections\") +\n  scale_fill_brewer(palette=\"Set1\") +\n  facet_wrap(~continent,ncol=1,scales=\"free\",strip.position=\"right\")\n\nEurope &lt;- democraticchanges |&gt; \n  filter(continent==\"Europe\") |&gt; \n  ggplot(aes(xmin=year,\n             xmax=year+1,\n             ymin=as.numeric(country_name)-.3,\n             ymax=as.numeric(country_name)+.3,\n             fill=has_free_and_fair_election)) +\n  geom_rect() +\n  ggflags::geom_flag(data=y_lab |&gt; \n                       filter(continent==\"Europe\"),\n                     mapping=aes(y=y_mid,country=tolower(iso2),x=1945),inherit.aes=FALSE) +\n  scale_y_continuous(breaks=y_lab$y_mid,labels=y_lab$country_name) +\n  theme_minimal() +\n  theme(legend.position=\"bottom\",\n        legend.text=element_text(size=7),\n        legend.title=element_text(size=7)) +\n  labs(x=\"\",\n       y=\"\",\n       fill=\"Has Free and Fair Elections\") +\n  scale_fill_brewer(palette=\"Set1\") +\n  facet_wrap(~continent,ncol=1,scales=\"free\",strip.position=\"right\")\n\n## Let's take advantage of patchwork to plot these graphs next to each other with a common legend\nlibrary(patchwork)\nEurope + Africa + plot_layout(guides = 'collect') & theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\nThis is fun! Let’s make a map and animate it.\n\n\n\nOne can see at a glance that, in Europe, there appears to be a democratic progression. Similarly, in Africa, there is a progression, but there is also backsliding. It would also be really useful to see this as a map - moreover, it would be really interesting to see as an animated map.\nrnaturalearth is a package that allows you to easily download map borders. Patrice Ferlet keeps a dataset of the centroid for countries that we can plot the flags on as well.\n\n\nCode in R\nlibrary(rnaturalearth)\n\nworld &lt;- ne_countries(type=\"countries\",returnclass=\"sf\")\n\ncoord &lt;- read_csv(\"https://gist.github.com/metal3d/5b925077e66194551df949de64e910f6/raw/c5f20a037409d96958553e2eb6b8251265c6fd63/country-coord.csv\") |&gt; \n  mutate(`Alpha-2 code`=replace_na(`Alpha-2 code`,\"NA\")) |&gt; \n  rename(code=`Alpha-2 code`,\n         lat=`Latitude (average)`,\n         lon=`Longitude (average)`)\n\n\nNow let’s take the democracy dataset from earlier, and left_join the dataset to the lat/long dataset as well as the world dataset\n\n\nCode in R\ndemocracymap &lt;- democracy |&gt; \n  mutate(iso2=countrycode(country_name,\"country.name\",\"iso2c\"),\n         continent = countrycode(iso2, \"iso2c\", \"continent\")) |&gt; \n  select(country_name,year,has_free_and_fair_election,iso2,continent) |&gt; \n  left_join(coord |&gt;\n              select(code,lat,lon),by=c(\"iso2\"=\"code\"))\n\ndemocracymap &lt;- democracymap |&gt; \n  select(country_name,year,has_free_and_fair_election,iso2,lat,lon) |&gt; \n  left_join(world, by=c(\"iso2\"=\"iso_a2_eh\")) |&gt; \n  filter(!is.na(geometry)) |&gt; \n  mutate(year=as.integer(year)) #this is necessary for the animation to progress frame by frame\n\n\nWe build this layer by layer. We want a base map of current boundaries, so we can take the current dataset and bring in one year’s worth of data.\n\n\nCode in R\nmap &lt;- democracymap |&gt; \n  filter(year==2020, !is.na(geometry)) |&gt; \n  select(-year)\n\nmap |&gt; \n  ggplot() + geom_sf(aes(geometry=geometry))\n\n\n\n\n\nWorld Map\n\n\n\n\nThen we can layer this map easily. Notice that the latitude and longitude signs are not typical of a map - the excellent metR package includes helpful themes and scales for meteorological data, which applies to maps as well!\n\n\nCode in R\ndemocracymap2 &lt;- democracymap |&gt; \n  filter(has_free_and_fair_election==TRUE)\n\nlibrary(metR)\n\nmap |&gt; \n  ggplot() +\n  geom_sf(mapping=aes(geometry=geometry),fill=\"white\",color=\"black\") +\n  geom_sf(data=democracymap2,\n          mapping=aes(geometry=geometry),color=NA,fill=\"blue\",\n          show.legend=FALSE)+\n  scale_x_longitude() +\n  scale_y_latitude() +\n  facet_wrap(~year) +\n  theme_bw() +\n  theme(axis.text=element_blank(),\n        axis.ticks=element_blank(),\n        strip.text=element_text(size=8,\n                                margin = margin(0,0,0,0, \"cm\")))\n\n\n\n\n\nA facet of the world\n\n\n\n\nThis map is a bit overwhelming, let’s use gganimate and focus on Europe and Africa. Comments below to walk through the European one. Because it’s tough to render, I saved it locally and then loaded it up on the website. Hooray!\n\n\nCode in R\n#Europe\n#First a base layer\nEurope2 &lt;- map |&gt; \n  filter(continent==\"Europe\") |&gt; \n  ggplot() +\n  # note that fill is the inside and color is the border in geom_sf\n  geom_sf(mapping=aes(geometry=geometry),fill=\"white\",color=\"black\") +\n#Then the democracy data\n  geom_sf(data=democracymap2 |&gt; \n            filter(continent==\"Europe\"),\n          mapping=aes(geometry=geometry),\n          color=\"black\",\n          show.legend=FALSE) +\n  ggflags::geom_flag(data=democracymap2 |&gt; \n                       filter(continent==\"Europe\",\n                              has_free_and_fair_election==TRUE),\n                     mapping=aes(y=lat,x=lon,country=tolower(iso2)),\n                     inherit.aes=FALSE) +\n  # gganimate allows you to use {closest_state} to fill in the transition label\n  labs(title= 'Year: {closest_state}') +\n  #metR scales\n  scale_x_longitude() +\n  scale_y_latitude() +\n  #gganimate transitions for the gif\n  transition_states(year) +\n  theme_bw() +\n  coord_sf(xlim=c(-20,40),\n           ylim=c(30,70),\n           default_crs=sf::st_crs(4326))\n\n#anim_save(filename=\"img/Europe.gif\",animation=Europe2)\n\n\n\n\n\nFree and Fair Elections in Europe\n\n\n\n\nCode in R\n#Africa\nAfrica2 &lt;- map |&gt; \n  filter(continent==\"Africa\") |&gt; \n  ggplot() +\n  geom_sf(mapping=aes(geometry=geometry),fill=\"white\",color=\"black\") +\n  geom_sf(data=democracymap2 |&gt; \n            filter(continent==\"Africa\"),\n          mapping=aes(geometry=geometry),color=\"black\",\n          show.legend=FALSE) +\n  scale_x_longitude() +\n  scale_y_latitude() +\n  ggflags::geom_flag(data=democracymap2 |&gt; \n                       filter(continent==\"Africa\",\n                              has_free_and_fair_election==TRUE),\n                     mapping=aes(y=lat,x=lon,\n                                 country=tolower(iso2)),\n                     inherit.aes=FALSE) +\n  labs(title = 'Year: {closest_state}') +\n  theme_bw() +\n  transition_states(year) +\n  coord_sf(default_crs=sf::st_crs(4326))\n\n#anim_save(filename=\"img/Africa.gif\",animation=Africa2)\n\n\n\n\n\nFree and Fair Elections in Africa"
  },
  {
    "objectID": "posts/2024-01-13-gganimate-ggflag/index.html#loading-and-exploring-a-tidy-tuesday-dataset",
    "href": "posts/2024-01-13-gganimate-ggflag/index.html#loading-and-exploring-a-tidy-tuesday-dataset",
    "title": "Using gganimate and ggflags to look at democratic progress",
    "section": "",
    "text": "One of my New Year’s resolutions was to become less of a lurker and more of a doer within the Tidy Tuesday community. There had been one dataset that I was super interested in exploring, based on Democracy and Dictatorship. Loaded the dataset and a few packages.\n\n\nCode in R\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\nlibrary(countrycode) #this package looks up ISO codes, which can be useful\nlibrary(ggflags) #pulls flags\nlibrary(gganimate) #animations\n\ndat &lt;- tidytuesdayR::tt_load(2024, week = 45)\ndemocracy &lt;- dat$democracy_data\n\nhead(democracy)\n\n\n# A tibble: 6 × 43\n  country_name country_code  year regime_category_index regime_category   \n  &lt;chr&gt;        &lt;chr&gt;        &lt;dbl&gt;                 &lt;dbl&gt; &lt;chr&gt;             \n1 Afghanistan  AFG           1950                     5 Royal dictatorship\n2 Afghanistan  AFG           1951                     5 Royal dictatorship\n3 Afghanistan  AFG           1952                     5 Royal dictatorship\n4 Afghanistan  AFG           1953                     5 Royal dictatorship\n5 Afghanistan  AFG           1954                     5 Royal dictatorship\n6 Afghanistan  AFG           1955                     5 Royal dictatorship\n# ℹ 38 more variables: is_monarchy &lt;lgl&gt;, is_commonwealth &lt;lgl&gt;,\n#   monarch_name &lt;chr&gt;, monarch_accession_year &lt;dbl&gt;, monarch_birthyear &lt;dbl&gt;,\n#   is_female_monarch &lt;lgl&gt;, is_democracy &lt;lgl&gt;, is_presidential &lt;lgl&gt;,\n#   president_name &lt;chr&gt;, president_accesion_year &lt;dbl&gt;,\n#   president_birthyear &lt;dbl&gt;, is_interim_phase &lt;lgl&gt;,\n#   is_female_president &lt;lgl&gt;, is_colony &lt;lgl&gt;, colony_of &lt;chr&gt;,\n#   colony_administrated_by &lt;chr&gt;, is_communist &lt;lgl&gt;, …\n\n\nThis dataset shows, for every year from 1950 to 2000, classifications for countries around the world. In the spirit of January 6th, I chose to focus on whether countries have free and fair elections, here shown as has_free_and_fair_election.\nIn the interest of this exploration, I’m not interested in colonies, which are shown as NA in the regime_category_index.\n\n\nCode in R\ndemocracy &lt;- democracy |&gt; \n  ## removing colonies as much as possible to get down to countries\n  filter(!is.na(regime_category_index),\n         ## British Virgin Islands oddly keeps showing up in spite of status as colony\n         country_code!=\"VGB\") \n\n\n\n\nMy first inclination in the dataset was to take out the countries that only had free and fair elections or a lack thereof, in order to understand places that had democratic progress and democratic backsliding. This required setting up a filter for this work. tabyl from the janitor package is well set up for this, as it will quickly come up with cross counts.\n\n\nCode in R\ndemocracyfilter &lt;- democracy |&gt; \n  janitor::tabyl(country_name,has_free_and_fair_election) |&gt; \n  filter(`TRUE` &gt; 0 & `FALSE` &gt; 0)\n\n\nThis gives a nice filter for this work. In order to use the ggflags package, you need for the countries to be spelled out in iso2c format. Fortunately, the amazing countrycodes package will do that for you, and in addition, it can provide the continent for you as well, for additional explorations.\n\n\nCode in R\ndemocraticchanges &lt;- democracy |&gt; \n  inner_join(democracyfilter) |&gt; \n  mutate(iso2=countrycode(country_name,\"country.name\",\"iso2c\"),\n         continent = countrycode(iso2, \"iso2c\", \"continent\")) |&gt; \n  arrange(continent,`FALSE`) |&gt; \n         mutate(country_name=fct_inorder(country_name))\n\n\nNow we are ready to plot this with the help of the ggflags package. Let’s look at Europe and Africa, two continents associated with democratic progress and backsliding.\nThere is one big issue - we would like for this to show up as continuous bars, which your typical geoms will not do. However, we can think of the bars as parts of a rectangle, that extend from the beginning to end of each year. If we factor the countries, we can then plot them and rename the y axis at the end.\n\n\nCode in R\n## Let's create the y-labels for later on\ny_lab &lt;- democraticchanges |&gt; \n  distinct(country_name,iso2,continent)  |&gt; \n  mutate(y_mid = as.numeric(country_name),\n         name=country_name)\n## For Africa\nAfrica &lt;- democraticchanges |&gt; \n  filter(continent==\"Africa\") |&gt; \n  ggplot(aes(xmin=year, #left boundary of the rectangle\n             xmax=year+1, #right boundary of the rectangle\n             ymin=as.numeric(country_name)-.3, #lower boundary of the rectangle\n             ymax=as.numeric(country_name)+.3, #upper boundary of the rectangle\n             fill=has_free_and_fair_election)) +\n  geom_rect() +\n  # now let's plot flags between the rectangles and the y axis\n  ggflags::geom_flag(data=y_lab |&gt; \n                       filter(continent==\"Africa\"),\n                     mapping=aes(y=y_mid,\n                                 country=tolower(iso2), #ggflags needs lowercase iso2 to work\n                                 x=1945),\n                     inherit.aes=FALSE) + #we want this to be individual to this layer\n                     #now to rename the y axis\n  scale_y_continuous(breaks=y_lab$y_mid,labels=y_lab$country_name) +\n  theme_minimal() +\n  theme(legend.position=\"bottom\",\n        legend.text=element_text(size=7),\n        legend.title=element_text(size=7)) +\n  labs(x=\"\",\n       y=\"\",\n       fill=\"Has Free and Fair Elections\") +\n  scale_fill_brewer(palette=\"Set1\") +\n  facet_wrap(~continent,ncol=1,scales=\"free\",strip.position=\"right\")\n\nEurope &lt;- democraticchanges |&gt; \n  filter(continent==\"Europe\") |&gt; \n  ggplot(aes(xmin=year,\n             xmax=year+1,\n             ymin=as.numeric(country_name)-.3,\n             ymax=as.numeric(country_name)+.3,\n             fill=has_free_and_fair_election)) +\n  geom_rect() +\n  ggflags::geom_flag(data=y_lab |&gt; \n                       filter(continent==\"Europe\"),\n                     mapping=aes(y=y_mid,country=tolower(iso2),x=1945),inherit.aes=FALSE) +\n  scale_y_continuous(breaks=y_lab$y_mid,labels=y_lab$country_name) +\n  theme_minimal() +\n  theme(legend.position=\"bottom\",\n        legend.text=element_text(size=7),\n        legend.title=element_text(size=7)) +\n  labs(x=\"\",\n       y=\"\",\n       fill=\"Has Free and Fair Elections\") +\n  scale_fill_brewer(palette=\"Set1\") +\n  facet_wrap(~continent,ncol=1,scales=\"free\",strip.position=\"right\")\n\n## Let's take advantage of patchwork to plot these graphs next to each other with a common legend\nlibrary(patchwork)\nEurope + Africa + plot_layout(guides = 'collect') & theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\nThis is fun! Let’s make a map and animate it.\n\n\n\nOne can see at a glance that, in Europe, there appears to be a democratic progression. Similarly, in Africa, there is a progression, but there is also backsliding. It would also be really useful to see this as a map - moreover, it would be really interesting to see as an animated map.\nrnaturalearth is a package that allows you to easily download map borders. Patrice Ferlet keeps a dataset of the centroid for countries that we can plot the flags on as well.\n\n\nCode in R\nlibrary(rnaturalearth)\n\nworld &lt;- ne_countries(type=\"countries\",returnclass=\"sf\")\n\ncoord &lt;- read_csv(\"https://gist.github.com/metal3d/5b925077e66194551df949de64e910f6/raw/c5f20a037409d96958553e2eb6b8251265c6fd63/country-coord.csv\") |&gt; \n  mutate(`Alpha-2 code`=replace_na(`Alpha-2 code`,\"NA\")) |&gt; \n  rename(code=`Alpha-2 code`,\n         lat=`Latitude (average)`,\n         lon=`Longitude (average)`)\n\n\nNow let’s take the democracy dataset from earlier, and left_join the dataset to the lat/long dataset as well as the world dataset\n\n\nCode in R\ndemocracymap &lt;- democracy |&gt; \n  mutate(iso2=countrycode(country_name,\"country.name\",\"iso2c\"),\n         continent = countrycode(iso2, \"iso2c\", \"continent\")) |&gt; \n  select(country_name,year,has_free_and_fair_election,iso2,continent) |&gt; \n  left_join(coord |&gt;\n              select(code,lat,lon),by=c(\"iso2\"=\"code\"))\n\ndemocracymap &lt;- democracymap |&gt; \n  select(country_name,year,has_free_and_fair_election,iso2,lat,lon) |&gt; \n  left_join(world, by=c(\"iso2\"=\"iso_a2_eh\")) |&gt; \n  filter(!is.na(geometry)) |&gt; \n  mutate(year=as.integer(year)) #this is necessary for the animation to progress frame by frame\n\n\nWe build this layer by layer. We want a base map of current boundaries, so we can take the current dataset and bring in one year’s worth of data.\n\n\nCode in R\nmap &lt;- democracymap |&gt; \n  filter(year==2020, !is.na(geometry)) |&gt; \n  select(-year)\n\nmap |&gt; \n  ggplot() + geom_sf(aes(geometry=geometry))\n\n\n\n\n\nWorld Map\n\n\n\n\nThen we can layer this map easily. Notice that the latitude and longitude signs are not typical of a map - the excellent metR package includes helpful themes and scales for meteorological data, which applies to maps as well!\n\n\nCode in R\ndemocracymap2 &lt;- democracymap |&gt; \n  filter(has_free_and_fair_election==TRUE)\n\nlibrary(metR)\n\nmap |&gt; \n  ggplot() +\n  geom_sf(mapping=aes(geometry=geometry),fill=\"white\",color=\"black\") +\n  geom_sf(data=democracymap2,\n          mapping=aes(geometry=geometry),color=NA,fill=\"blue\",\n          show.legend=FALSE)+\n  scale_x_longitude() +\n  scale_y_latitude() +\n  facet_wrap(~year) +\n  theme_bw() +\n  theme(axis.text=element_blank(),\n        axis.ticks=element_blank(),\n        strip.text=element_text(size=8,\n                                margin = margin(0,0,0,0, \"cm\")))\n\n\n\n\n\nA facet of the world\n\n\n\n\nThis map is a bit overwhelming, let’s use gganimate and focus on Europe and Africa. Comments below to walk through the European one. Because it’s tough to render, I saved it locally and then loaded it up on the website. Hooray!\n\n\nCode in R\n#Europe\n#First a base layer\nEurope2 &lt;- map |&gt; \n  filter(continent==\"Europe\") |&gt; \n  ggplot() +\n  # note that fill is the inside and color is the border in geom_sf\n  geom_sf(mapping=aes(geometry=geometry),fill=\"white\",color=\"black\") +\n#Then the democracy data\n  geom_sf(data=democracymap2 |&gt; \n            filter(continent==\"Europe\"),\n          mapping=aes(geometry=geometry),\n          color=\"black\",\n          show.legend=FALSE) +\n  ggflags::geom_flag(data=democracymap2 |&gt; \n                       filter(continent==\"Europe\",\n                              has_free_and_fair_election==TRUE),\n                     mapping=aes(y=lat,x=lon,country=tolower(iso2)),\n                     inherit.aes=FALSE) +\n  # gganimate allows you to use {closest_state} to fill in the transition label\n  labs(title= 'Year: {closest_state}') +\n  #metR scales\n  scale_x_longitude() +\n  scale_y_latitude() +\n  #gganimate transitions for the gif\n  transition_states(year) +\n  theme_bw() +\n  coord_sf(xlim=c(-20,40),\n           ylim=c(30,70),\n           default_crs=sf::st_crs(4326))\n\n#anim_save(filename=\"img/Europe.gif\",animation=Europe2)\n\n\n\n\n\nFree and Fair Elections in Europe\n\n\n\n\nCode in R\n#Africa\nAfrica2 &lt;- map |&gt; \n  filter(continent==\"Africa\") |&gt; \n  ggplot() +\n  geom_sf(mapping=aes(geometry=geometry),fill=\"white\",color=\"black\") +\n  geom_sf(data=democracymap2 |&gt; \n            filter(continent==\"Africa\"),\n          mapping=aes(geometry=geometry),color=\"black\",\n          show.legend=FALSE) +\n  scale_x_longitude() +\n  scale_y_latitude() +\n  ggflags::geom_flag(data=democracymap2 |&gt; \n                       filter(continent==\"Africa\",\n                              has_free_and_fair_election==TRUE),\n                     mapping=aes(y=lat,x=lon,\n                                 country=tolower(iso2)),\n                     inherit.aes=FALSE) +\n  labs(title = 'Year: {closest_state}') +\n  theme_bw() +\n  transition_states(year) +\n  coord_sf(default_crs=sf::st_crs(4326))\n\n#anim_save(filename=\"img/Africa.gif\",animation=Africa2)\n\n\n\n\n\nFree and Fair Elections in Africa"
  },
  {
    "objectID": "posts/2025-01-05-fuzzyjoin-in-action/index.html",
    "href": "posts/2025-01-05-fuzzyjoin-in-action/index.html",
    "title": "Using fuzzyjoin to work with NCES data",
    "section": "",
    "text": "Like families, tidy datasets are all alike but every messy dataset is messy in its own way. - Hadley Wickham\n\nWe often work with datasets where there is a unique identifier that can be used to link or filter the data, typically involving some type of a join.\nHowever, sometimes the identifiers that we wish to use to join are near matches. For instance, maybe you are joining a dataset by names, where one dataset has John, and the dataset you are joining has john. Or maybe there are text entry errors and it is instead Jon.\nWhat you need is a way to join data that is a little bit fuzzy. Enter (David Robinson)[https://github.com/dgrtwo/fuzzyjoin]’s excellent fuzzyjoin package.\n\n\nThere are 20 schools listed in the public school database for the National Center for Education Statistics in the Virgin Islands. I’ve downloaded the dataset and you can pull it from my github repo through the code below. A scrollable DT table to explore below (disabling a lot of features just to see the table):\n\n\nCode in R\nlibrary(tidyverse)\nlibrary(fuzzyjoin)\nlibrary(kableExtra)\nVI &lt;- read_csv(\"https://github.com/drjohnrussell/drjohnrussell.github.io/raw/refs/heads/master/posts/2025-01-05-fuzzyjoin-in-action/data/VIschools.csv\")\n\nVI |&gt; \n  kbl() |&gt; \n  kable_paper() |&gt; ##nice theme\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) |&gt; \n  scroll_box(height = \"200px\") ##adds scrolling\n\n\n\n\nPublic Schools of Virgin Islands\n\n\nschoolname\nnces\ndistrict\naddress\nstate\nlow_grade\nhi_grade\ntotal\n\n\n\n\nAlfredo Andrews Elementary School\n780000200002\nSaint Croix School District\nRFD 1 KINGSHILL\nVI\nPK\n06\n495\n\n\nClaude O. Markoe Elementary School\n780000200006\nSaint Croix School District\nPLOTS 71 75 MARS HILL\nVI\nPK\n06\n403\n\n\nEulalie Rivera\n780000200011\nSaint Croix School District\nROUTE 1 GROVE PLACE\nVI\nPK\n08\n645\n\n\nSt. Croix Educational Complex High School\n780000200013\nSaint Croix School District\nRR2 KINGSHILL\nVI\n09\n12\n893\n\n\nJuanita Gardine\n780000200021\nSaint Croix School District\nESTATE RICHMOND\nVI\nPK\n08\n305\n\n\nLew Muckle Elementary School\n780000200023\nSaint Croix School District\n317 SION FARM\nVI\nPK\n06\n339\n\n\nPearl B. Larsen\n780000200028\nSaint Croix School District\nESTATE ST PETERS\nVI\nPK\n08\n432\n\n\nRicardo Richards Elementary School\n780000200029\nSaint Croix School District\n491 BARREN SPOT\nVI\nPK\n06\n392\n\n\nSt. Croix Central High School\n780000200030\nSaint Croix School District\nRSD 2 KINGSHILL\nVI\n09\n12\n717\n\n\nJohn H. Woodson Junior High School\n780000200037\nSaint Croix School District\nRURAL ROUTE 1 KINGSHILL\nVI\n07\n08\n461\n\n\nCharlotte Amalie High School\n780003000005\nSaint Thomas - Saint John School District\n8 and 9 ESTATE THOMAS\nVI\n09\n12\n1076\n\n\nIvanna Eudora Kean High School\n780003000015\nSaint Thomas - Saint John School District\n1 and 2 ESTate NAZARETH\nVI\n09\n12\n738\n\n\nJane E. Tuitt Elementary School\n780003000018\nSaint Thomas - Saint John School District\n19 LEVOKI STRAEDE\nVI\nKG\n04\n154\n\n\nJoseph Gomez Elementary School\n780003000019\nSaint Thomas - Saint John School District\n142 ANNAS RETREAT\nVI\nPK\n05\n462\n\n\nJoseph Sibilly Elementary School\n780003000020\nSaint Thomas - Saint John School District\n14 15 16 ESTATE ELIZABETH\nVI\nPK\n05\n226\n\n\nJulius E. Sprauve School\n780003000022\nSaint Thomas - Saint John School District\n14 18 ESTATE ENIGHED\nVI\nPK\n08\n225\n\n\nLockhart Elementary School\n780003000024\nSaint Thomas - Saint John School District\n41 ESTATE THOMAS\nVI\nKG\n08\n977\n\n\nUlla F. Muller Elementary School\n780003000026\nSaint Thomas - Saint John School District\n7B ESTATE CONTANT\nVI\nPK\n05\n401\n\n\nYvonne E. Milliner-Bowsky Elementary School\n780003000027\nSaint Thomas - Saint John School District\n15B and 16 ESTATE MANDAHL\nVI\nPK\n05\n433\n\n\nBertha C. Boschulte Middle School\n780003000034\nSaint Thomas - Saint John School District\n9 1 and 12A BOVONI\nVI\n06\n08\n538\n\n\n\n\n\n\n\nLet’s say we have a dataset with the following names of schools, and we want to pull in information from NCES.\n\n\nCode in R\nsample &lt;- read_csv(\"https://github.com/drjohnrussell/drjohnrussell.github.io/raw/refs/heads/master/posts/2025-01-05-fuzzyjoin-in-action/data/sample.csv\")\n\nsample |&gt; \n  kbl() |&gt; \n  kable_paper()\n\n\n\nDataset to join\n\n\nschoolname\nstate\n\n\n\n\neulalie rivera\nVI\n\n\nJoseph Elementary School\nVI\n\n\nAlfredo Andrews Elementary School\nNY\n\n\n\n\n\n\n\nEnter the fuzzyjoin package, which allows the data to be messy in many ways, depending on what you need. Some of the ways to join outlined in the package are as follows:\n\ndifference_join - joins that are numeric and within a specified distance\ngeo_join - joins that use distances based on latitude and longitude\nregex_join - joins that look for common regex patterns (text and position)\nstringdist_join - joins that take into account small differences in the string\n\nLet’s focus on stringdist_join for special case uses.\n\n\n\nJoins that ignore case, where you don’t have to mutate using something like the stringr str_to_lower on the data to change it is a big win. We can use it to match eulalie rivera.\nThis is what would happen as is:\n\n\nCode in R\nsample[1,1] |&gt; \n  inner_join(VI,by=c(\"schoolname\")) |&gt; \n  kbl() |&gt; \n  kable_paper()\n\n\n\nAn empty inner join\n\n\nschoolname\nnces\ndistrict\naddress\nstate\nlow_grade\nhi_grade\ntotal\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn the other hand, we can use the stringdist_join and set ignore_case to equal TRUE.\n\n\nCode in R\nsample[1,1] |&gt; \n  stringdist_join(VI,\n                  by=c(\"schoolname\"),\n                  max_dist=0,\n                  mode=\"inner\",\n                  ignore_case=TRUE) |&gt; \n  kbl() |&gt; \n  kable_paper()\n\n\n\nA successful join\n\n\nschoolname.x\nschoolname.y\nnces\ndistrict\naddress\nstate\nlow_grade\nhi_grade\ntotal\n\n\n\n\neulalie rivera\nEulalie Rivera\n780000200011\nSaint Croix School District\nROUTE 1 GROVE PLACE\nVI\nPK\n08\n645\n\n\n\n\n\n\n\n\n\n\nThe way that I’ve taken advantage of this is in dealing with typos or data where someone may have subtly different names for a school (e.g., one has the word school while the other drops it). What is nice about the fuzzyjoin package is that you can do the join. What is less nice is that it requires you to do a line check afterwards, especially when you are loose with the distances.\nLet’s look at the second row, Joseph Elementary School, and have a maximum distance of 8.\n\n\nCode in R\nsample[2,1] |&gt; \n  stringdist_join(VI,\n                   by=\"schoolname\",\n                   max_dist=8,\n                   mode=\"inner\",\n                   ignore_case=TRUE,\n                  distance_col=\"stringdistance\") |&gt; \n  kbl() |&gt; \n  kable_paper()\n\n\n\nMultiple rows loosely match\n\n\nschoolname.x\nschoolname.y\nnces\ndistrict\naddress\nstate\nlow_grade\nhi_grade\ntotal\nstringdistance\n\n\n\n\nJoseph Elementary School\nJoseph Gomez Elementary School\n7.80003e+11\nSaint Thomas - Saint John School District\n142 ANNAS RETREAT\nVI\nPK\n05\n462\n6\n\n\nJoseph Elementary School\nJoseph Sibilly Elementary School\n7.80003e+11\nSaint Thomas - Saint John School District\n14 15 16 ESTATE ELIZABETH\nVI\nPK\n05\n226\n8\n\n\nJoseph Elementary School\nLockhart Elementary School\n7.80003e+11\nSaint Thomas - Saint John School District\n41 ESTATE THOMAS\nVI\nKG\n08\n977\n7\n\n\n\n\n\n\n\nYou can see the power, and the danger, of the fuzzyjoin package here. It’s amazing that it picks up the two schools that also have Joseph in their name, but it also suggests that you could change a few letters in the beginning and form the name of another school.\nWhen we used fuzzyjoin, we would arrange the data by the school name and then the distance_col variable so that we could easily do a line check and choose the best match (if available).\n\n\n\nAs a side note, it is nice to use the fuzzyjoin package for seeing errors in multiple columns. Here we can see how it works with the third row of the dataset.\n\n\nCode in R\nsample[3,] |&gt; \n  stringdist_join(VI,\n                  by=c(\"schoolname\",\"state\"),\n                  mode=\"inner\",\n                  max_dist = 4,\n                  ignore_case=TRUE,\n                  distance_col=\"stringdistance\") |&gt; \n  kbl() |&gt; \n  kable_paper()\n\n\n\n\n\nschoolname.x\nstate.x\nschoolname.y\nnces\ndistrict\naddress\nstate.y\nlow_grade\nhi_grade\ntotal\nschoolname.stringdistance\nstate.stringdistance\nstringdistance\n\n\n\n\nAlfredo Andrews Elementary School\nNY\nAlfredo Andrews Elementary School\n780000200002\nSaint Croix School District\nRFD 1 KINGSHILL\nVI\nPK\n06\n495\n0\n2\nNA"
  },
  {
    "objectID": "posts/2025-01-05-fuzzyjoin-in-action/index.html#introducing-an-example---schools-in-the-virgin-islands",
    "href": "posts/2025-01-05-fuzzyjoin-in-action/index.html#introducing-an-example---schools-in-the-virgin-islands",
    "title": "Using fuzzyjoin to work with NCES data",
    "section": "",
    "text": "There are 20 schools listed in the public school database for the National Center for Education Statistics in the Virgin Islands. I’ve downloaded the dataset and you can pull it from my github repo through the code below. A scrollable DT table to explore below (disabling a lot of features just to see the table):\n\n\nCode in R\nlibrary(tidyverse)\nlibrary(fuzzyjoin)\nlibrary(kableExtra)\nVI &lt;- read_csv(\"https://github.com/drjohnrussell/drjohnrussell.github.io/raw/refs/heads/master/posts/2025-01-05-fuzzyjoin-in-action/data/VIschools.csv\")\n\nVI |&gt; \n  kbl() |&gt; \n  kable_paper() |&gt; ##nice theme\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) |&gt; \n  scroll_box(height = \"200px\") ##adds scrolling\n\n\n\n\nPublic Schools of Virgin Islands\n\n\nschoolname\nnces\ndistrict\naddress\nstate\nlow_grade\nhi_grade\ntotal\n\n\n\n\nAlfredo Andrews Elementary School\n780000200002\nSaint Croix School District\nRFD 1 KINGSHILL\nVI\nPK\n06\n495\n\n\nClaude O. Markoe Elementary School\n780000200006\nSaint Croix School District\nPLOTS 71 75 MARS HILL\nVI\nPK\n06\n403\n\n\nEulalie Rivera\n780000200011\nSaint Croix School District\nROUTE 1 GROVE PLACE\nVI\nPK\n08\n645\n\n\nSt. Croix Educational Complex High School\n780000200013\nSaint Croix School District\nRR2 KINGSHILL\nVI\n09\n12\n893\n\n\nJuanita Gardine\n780000200021\nSaint Croix School District\nESTATE RICHMOND\nVI\nPK\n08\n305\n\n\nLew Muckle Elementary School\n780000200023\nSaint Croix School District\n317 SION FARM\nVI\nPK\n06\n339\n\n\nPearl B. Larsen\n780000200028\nSaint Croix School District\nESTATE ST PETERS\nVI\nPK\n08\n432\n\n\nRicardo Richards Elementary School\n780000200029\nSaint Croix School District\n491 BARREN SPOT\nVI\nPK\n06\n392\n\n\nSt. Croix Central High School\n780000200030\nSaint Croix School District\nRSD 2 KINGSHILL\nVI\n09\n12\n717\n\n\nJohn H. Woodson Junior High School\n780000200037\nSaint Croix School District\nRURAL ROUTE 1 KINGSHILL\nVI\n07\n08\n461\n\n\nCharlotte Amalie High School\n780003000005\nSaint Thomas - Saint John School District\n8 and 9 ESTATE THOMAS\nVI\n09\n12\n1076\n\n\nIvanna Eudora Kean High School\n780003000015\nSaint Thomas - Saint John School District\n1 and 2 ESTate NAZARETH\nVI\n09\n12\n738\n\n\nJane E. Tuitt Elementary School\n780003000018\nSaint Thomas - Saint John School District\n19 LEVOKI STRAEDE\nVI\nKG\n04\n154\n\n\nJoseph Gomez Elementary School\n780003000019\nSaint Thomas - Saint John School District\n142 ANNAS RETREAT\nVI\nPK\n05\n462\n\n\nJoseph Sibilly Elementary School\n780003000020\nSaint Thomas - Saint John School District\n14 15 16 ESTATE ELIZABETH\nVI\nPK\n05\n226\n\n\nJulius E. Sprauve School\n780003000022\nSaint Thomas - Saint John School District\n14 18 ESTATE ENIGHED\nVI\nPK\n08\n225\n\n\nLockhart Elementary School\n780003000024\nSaint Thomas - Saint John School District\n41 ESTATE THOMAS\nVI\nKG\n08\n977\n\n\nUlla F. Muller Elementary School\n780003000026\nSaint Thomas - Saint John School District\n7B ESTATE CONTANT\nVI\nPK\n05\n401\n\n\nYvonne E. Milliner-Bowsky Elementary School\n780003000027\nSaint Thomas - Saint John School District\n15B and 16 ESTATE MANDAHL\nVI\nPK\n05\n433\n\n\nBertha C. Boschulte Middle School\n780003000034\nSaint Thomas - Saint John School District\n9 1 and 12A BOVONI\nVI\n06\n08\n538\n\n\n\n\n\n\n\nLet’s say we have a dataset with the following names of schools, and we want to pull in information from NCES.\n\n\nCode in R\nsample &lt;- read_csv(\"https://github.com/drjohnrussell/drjohnrussell.github.io/raw/refs/heads/master/posts/2025-01-05-fuzzyjoin-in-action/data/sample.csv\")\n\nsample |&gt; \n  kbl() |&gt; \n  kable_paper()\n\n\n\nDataset to join\n\n\nschoolname\nstate\n\n\n\n\neulalie rivera\nVI\n\n\nJoseph Elementary School\nVI\n\n\nAlfredo Andrews Elementary School\nNY\n\n\n\n\n\n\n\nEnter the fuzzyjoin package, which allows the data to be messy in many ways, depending on what you need. Some of the ways to join outlined in the package are as follows:\n\ndifference_join - joins that are numeric and within a specified distance\ngeo_join - joins that use distances based on latitude and longitude\nregex_join - joins that look for common regex patterns (text and position)\nstringdist_join - joins that take into account small differences in the string\n\nLet’s focus on stringdist_join for special case uses."
  },
  {
    "objectID": "posts/2025-01-05-fuzzyjoin-in-action/index.html#joins-that-ignore-case",
    "href": "posts/2025-01-05-fuzzyjoin-in-action/index.html#joins-that-ignore-case",
    "title": "Using fuzzyjoin to work with NCES data",
    "section": "",
    "text": "Joins that ignore case, where you don’t have to mutate using something like the stringr str_to_lower on the data to change it is a big win. We can use it to match eulalie rivera.\nThis is what would happen as is:\n\n\nCode in R\nsample[1,1] |&gt; \n  inner_join(VI,by=c(\"schoolname\")) |&gt; \n  kbl() |&gt; \n  kable_paper()\n\n\n\nAn empty inner join\n\n\nschoolname\nnces\ndistrict\naddress\nstate\nlow_grade\nhi_grade\ntotal\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn the other hand, we can use the stringdist_join and set ignore_case to equal TRUE.\n\n\nCode in R\nsample[1,1] |&gt; \n  stringdist_join(VI,\n                  by=c(\"schoolname\"),\n                  max_dist=0,\n                  mode=\"inner\",\n                  ignore_case=TRUE) |&gt; \n  kbl() |&gt; \n  kable_paper()\n\n\n\nA successful join\n\n\nschoolname.x\nschoolname.y\nnces\ndistrict\naddress\nstate\nlow_grade\nhi_grade\ntotal\n\n\n\n\neulalie rivera\nEulalie Rivera\n780000200011\nSaint Croix School District\nROUTE 1 GROVE PLACE\nVI\nPK\n08\n645"
  },
  {
    "objectID": "posts/2025-01-05-fuzzyjoin-in-action/index.html#joins-that-take-advantage-of-string-distance",
    "href": "posts/2025-01-05-fuzzyjoin-in-action/index.html#joins-that-take-advantage-of-string-distance",
    "title": "Using fuzzyjoin to work with NCES data",
    "section": "",
    "text": "The way that I’ve taken advantage of this is in dealing with typos or data where someone may have subtly different names for a school (e.g., one has the word school while the other drops it). What is nice about the fuzzyjoin package is that you can do the join. What is less nice is that it requires you to do a line check afterwards, especially when you are loose with the distances.\nLet’s look at the second row, Joseph Elementary School, and have a maximum distance of 8.\n\n\nCode in R\nsample[2,1] |&gt; \n  stringdist_join(VI,\n                   by=\"schoolname\",\n                   max_dist=8,\n                   mode=\"inner\",\n                   ignore_case=TRUE,\n                  distance_col=\"stringdistance\") |&gt; \n  kbl() |&gt; \n  kable_paper()\n\n\n\nMultiple rows loosely match\n\n\nschoolname.x\nschoolname.y\nnces\ndistrict\naddress\nstate\nlow_grade\nhi_grade\ntotal\nstringdistance\n\n\n\n\nJoseph Elementary School\nJoseph Gomez Elementary School\n7.80003e+11\nSaint Thomas - Saint John School District\n142 ANNAS RETREAT\nVI\nPK\n05\n462\n6\n\n\nJoseph Elementary School\nJoseph Sibilly Elementary School\n7.80003e+11\nSaint Thomas - Saint John School District\n14 15 16 ESTATE ELIZABETH\nVI\nPK\n05\n226\n8\n\n\nJoseph Elementary School\nLockhart Elementary School\n7.80003e+11\nSaint Thomas - Saint John School District\n41 ESTATE THOMAS\nVI\nKG\n08\n977\n7\n\n\n\n\n\n\n\nYou can see the power, and the danger, of the fuzzyjoin package here. It’s amazing that it picks up the two schools that also have Joseph in their name, but it also suggests that you could change a few letters in the beginning and form the name of another school.\nWhen we used fuzzyjoin, we would arrange the data by the school name and then the distance_col variable so that we could easily do a line check and choose the best match (if available)."
  },
  {
    "objectID": "posts/2025-01-05-fuzzyjoin-in-action/index.html#matching-off-of-multiple-columns",
    "href": "posts/2025-01-05-fuzzyjoin-in-action/index.html#matching-off-of-multiple-columns",
    "title": "Using fuzzyjoin to work with NCES data",
    "section": "",
    "text": "As a side note, it is nice to use the fuzzyjoin package for seeing errors in multiple columns. Here we can see how it works with the third row of the dataset.\n\n\nCode in R\nsample[3,] |&gt; \n  stringdist_join(VI,\n                  by=c(\"schoolname\",\"state\"),\n                  mode=\"inner\",\n                  max_dist = 4,\n                  ignore_case=TRUE,\n                  distance_col=\"stringdistance\") |&gt; \n  kbl() |&gt; \n  kable_paper()\n\n\n\n\n\nschoolname.x\nstate.x\nschoolname.y\nnces\ndistrict\naddress\nstate.y\nlow_grade\nhi_grade\ntotal\nschoolname.stringdistance\nstate.stringdistance\nstringdistance\n\n\n\n\nAlfredo Andrews Elementary School\nNY\nAlfredo Andrews Elementary School\n780000200002\nSaint Croix School District\nRFD 1 KINGSHILL\nVI\nPK\n06\n495\n0\n2\nNA"
  },
  {
    "objectID": "posts/2025-01-13-gganimate-ggflag/index.html",
    "href": "posts/2025-01-13-gganimate-ggflag/index.html",
    "title": "Using gganimate and ggflags to look at democratic progress",
    "section": "",
    "text": "One of my New Year’s resolutions was to become less of a lurker and more of a doer within the Tidy Tuesday community. There had been one dataset that I was super interested in exploring, based on Democracy and Dictatorship. Loaded the dataset and a few packages.\n\n\nCode in R\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\nlibrary(countrycode) #this package looks up ISO codes, which can be useful\nlibrary(ggflags) #pulls flags\nlibrary(gganimate) #animations\n\ndat &lt;- tidytuesdayR::tt_load(2024, week = 45)\ndemocracy &lt;- dat$democracy_data\n\nhead(democracy)\n\n\n# A tibble: 6 × 43\n  country_name country_code  year regime_category_index regime_category   \n  &lt;chr&gt;        &lt;chr&gt;        &lt;dbl&gt;                 &lt;dbl&gt; &lt;chr&gt;             \n1 Afghanistan  AFG           1950                     5 Royal dictatorship\n2 Afghanistan  AFG           1951                     5 Royal dictatorship\n3 Afghanistan  AFG           1952                     5 Royal dictatorship\n4 Afghanistan  AFG           1953                     5 Royal dictatorship\n5 Afghanistan  AFG           1954                     5 Royal dictatorship\n6 Afghanistan  AFG           1955                     5 Royal dictatorship\n# ℹ 38 more variables: is_monarchy &lt;lgl&gt;, is_commonwealth &lt;lgl&gt;,\n#   monarch_name &lt;chr&gt;, monarch_accession_year &lt;dbl&gt;, monarch_birthyear &lt;dbl&gt;,\n#   is_female_monarch &lt;lgl&gt;, is_democracy &lt;lgl&gt;, is_presidential &lt;lgl&gt;,\n#   president_name &lt;chr&gt;, president_accesion_year &lt;dbl&gt;,\n#   president_birthyear &lt;dbl&gt;, is_interim_phase &lt;lgl&gt;,\n#   is_female_president &lt;lgl&gt;, is_colony &lt;lgl&gt;, colony_of &lt;chr&gt;,\n#   colony_administrated_by &lt;chr&gt;, is_communist &lt;lgl&gt;, …\n\n\nThis dataset shows, for every year from 1950 to 2000, classifications for countries around the world. In the spirit of January 6th, I chose to focus on whether countries have free and fair elections, here shown as has_free_and_fair_election.\nIn the interest of this exploration, I’m not interested in colonies, which are shown as NA in the regime_category_index.\n\n\nCode in R\ndemocracy &lt;- democracy |&gt; \n  ## removing colonies as much as possible to get down to countries\n  filter(!is.na(regime_category_index),\n         ## British Virgin Islands oddly keeps showing up in spite of status as colony\n         country_code!=\"VGB\") \n\n\n\n\nMy first inclination in the dataset was to take out the countries that only had free and fair elections or a lack thereof, in order to understand places that had democratic progress and democratic backsliding. This required setting up a filter for this work. tabyl from the janitor package is well set up for this, as it will quickly come up with cross counts.\n\n\nCode in R\ndemocracyfilter &lt;- democracy |&gt; \n  janitor::tabyl(country_name,has_free_and_fair_election) |&gt; \n  filter(`TRUE` &gt; 0 & `FALSE` &gt; 0)\n\n\nThis gives a nice filter for this work. In order to use the ggflags package, you need for the countries to be spelled out in iso2c format. Fortunately, the amazing countrycodes package will do that for you, and in addition, it can provide the continent for you as well, for additional explorations.\n\n\nCode in R\ndemocraticchanges &lt;- democracy |&gt; \n  inner_join(democracyfilter) |&gt; \n  mutate(iso2=countrycode(country_name,\"country.name\",\"iso2c\"),\n         continent = countrycode(iso2, \"iso2c\", \"continent\")) |&gt; \n  arrange(continent,`FALSE`) |&gt; \n         mutate(country_name=fct_inorder(country_name))\n\n\nNow we are ready to plot this with the help of the ggflags package. Let’s look at Europe and Africa, two continents associated with democratic progress and backsliding.\nThere is one big issue - we would like for this to show up as continuous bars, which your typical geoms will not do. However, we can think of the bars as parts of a rectangle, that extend from the beginning to end of each year. If we factor the countries, we can then plot them and rename the y axis at the end.\n\n\nCode in R\n## Let's create the y-labels for later on\ny_lab &lt;- democraticchanges |&gt; \n  distinct(country_name,iso2,continent)  |&gt; \n  mutate(y_mid = as.numeric(country_name),\n         name=country_name)\n## For Africa\nAfrica &lt;- democraticchanges |&gt; \n  filter(continent==\"Africa\") |&gt; \n  ggplot(aes(xmin=year, #left boundary of the rectangle\n             xmax=year+1, #right boundary of the rectangle\n             ymin=as.numeric(country_name)-.3, #lower boundary of the rectangle\n             ymax=as.numeric(country_name)+.3, #upper boundary of the rectangle\n             fill=has_free_and_fair_election)) +\n  geom_rect() +\n  # now let's plot flags between the rectangles and the y axis\n  ggflags::geom_flag(data=y_lab |&gt; \n                       filter(continent==\"Africa\"),\n                     mapping=aes(y=y_mid,\n                                 country=tolower(iso2), #ggflags needs lowercase iso2 to work\n                                 x=1945),\n                     inherit.aes=FALSE) + #we want this to be individual to this layer\n                     #now to rename the y axis\n  scale_y_continuous(breaks=y_lab$y_mid,labels=y_lab$country_name) +\n  theme_minimal() +\n  theme(legend.position=\"bottom\",\n        legend.text=element_text(size=7),\n        legend.title=element_text(size=7)) +\n  labs(x=\"\",\n       y=\"\",\n       fill=\"Has Free and Fair Elections\") +\n  scale_fill_brewer(palette=\"Set1\") +\n  facet_wrap(~continent,ncol=1,scales=\"free\",strip.position=\"right\")\n\nEurope &lt;- democraticchanges |&gt; \n  filter(continent==\"Europe\") |&gt; \n  ggplot(aes(xmin=year,\n             xmax=year+1,\n             ymin=as.numeric(country_name)-.3,\n             ymax=as.numeric(country_name)+.3,\n             fill=has_free_and_fair_election)) +\n  geom_rect() +\n  ggflags::geom_flag(data=y_lab |&gt; \n                       filter(continent==\"Europe\"),\n                     mapping=aes(y=y_mid,country=tolower(iso2),x=1945),inherit.aes=FALSE) +\n  scale_y_continuous(breaks=y_lab$y_mid,labels=y_lab$country_name) +\n  theme_minimal() +\n  theme(legend.position=\"bottom\",\n        legend.text=element_text(size=7),\n        legend.title=element_text(size=7)) +\n  labs(x=\"\",\n       y=\"\",\n       fill=\"Has Free and Fair Elections\") +\n  scale_fill_brewer(palette=\"Set1\") +\n  facet_wrap(~continent,ncol=1,scales=\"free\",strip.position=\"right\")\n\n## Let's take advantage of patchwork to plot these graphs next to each other with a common legend\nlibrary(patchwork)\nEurope + Africa + plot_layout(guides = 'collect') & theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\nThis is fun! Let’s make a map and animate it.\n\n\n\nOne can see at a glance that, in Europe, there appears to be a democratic progression. Similarly, in Africa, there is a progression, but there is also backsliding. It would also be really useful to see this as a map - moreover, it would be really interesting to see as an animated map.\nrnaturalearth is a package that allows you to easily download map borders. Patrice Ferlet keeps a dataset of the centroid for countries that we can plot the flags on as well.\n\n\nCode in R\nlibrary(rnaturalearth)\n\nworld &lt;- ne_countries(type=\"countries\",returnclass=\"sf\")\n\ncoord &lt;- read_csv(\"https://gist.github.com/metal3d/5b925077e66194551df949de64e910f6/raw/c5f20a037409d96958553e2eb6b8251265c6fd63/country-coord.csv\") |&gt; \n  mutate(`Alpha-2 code`=replace_na(`Alpha-2 code`,\"NA\")) |&gt; \n  rename(code=`Alpha-2 code`,\n         lat=`Latitude (average)`,\n         lon=`Longitude (average)`)\n\n\nNow let’s take the democracy dataset from earlier, and left_join the dataset to the lat/long dataset as well as the world dataset\n\n\nCode in R\ndemocracymap &lt;- democracy |&gt; \n  mutate(iso2=countrycode(country_name,\"country.name\",\"iso2c\"),\n         continent = countrycode(iso2, \"iso2c\", \"continent\")) |&gt; \n  select(country_name,year,has_free_and_fair_election,iso2,continent) |&gt; \n  left_join(coord |&gt;\n              select(code,lat,lon),by=c(\"iso2\"=\"code\"))\n\ndemocracymap &lt;- democracymap |&gt; \n  select(country_name,year,has_free_and_fair_election,iso2,lat,lon) |&gt; \n  left_join(world, by=c(\"iso2\"=\"iso_a2_eh\")) |&gt; \n  filter(!is.na(geometry)) |&gt; \n  mutate(year=as.integer(year)) #this is necessary for the animation to progress frame by frame\n\n\nWe build this layer by layer. We want a base map of current boundaries, so we can take the current dataset and bring in one year’s worth of data.\n\n\nCode in R\nmap &lt;- democracymap |&gt; \n  filter(year==2020, !is.na(geometry)) |&gt; \n  select(-year)\n\nmap |&gt; \n  ggplot() + geom_sf(aes(geometry=geometry))\n\n\n\n\n\nWorld Map\n\n\n\n\nThen we can layer this map easily. Notice that the latitude and longitude signs are not typical of a map - the excellent metR package includes helpful themes and scales for meteorological data, which applies to maps as well!\n\n\nCode in R\ndemocracymap2 &lt;- democracymap |&gt; \n  filter(has_free_and_fair_election==TRUE)\n\nlibrary(metR)\n\nmap |&gt; \n  ggplot() +\n  geom_sf(mapping=aes(geometry=geometry),fill=\"white\",color=\"black\") +\n  geom_sf(data=democracymap2,\n          mapping=aes(geometry=geometry),color=NA,fill=\"blue\",\n          show.legend=FALSE)+\n  scale_x_longitude() +\n  scale_y_latitude() +\n  facet_wrap(~year) +\n  theme_bw() +\n  theme(axis.text=element_blank(),\n        axis.ticks=element_blank(),\n        strip.text=element_text(size=8,\n                                margin = margin(0,0,0,0, \"cm\")))\n\n\n\n\n\nA facet of the world\n\n\n\n\nThis map is a bit overwhelming, let’s use gganimate and focus on Europe and Africa. Comments below to walk through the European one. Because it’s tough to render, I saved it locally and then loaded it up on the website. Hooray!\n\n\nCode in R\n#Europe\n#First a base layer\nEurope2 &lt;- map |&gt; \n  filter(continent==\"Europe\") |&gt; \n  ggplot() +\n  # note that fill is the inside and color is the border in geom_sf\n  geom_sf(mapping=aes(geometry=geometry),fill=\"white\",color=\"black\") +\n#Then the democracy data\n  geom_sf(data=democracymap2 |&gt; \n            filter(continent==\"Europe\"),\n          mapping=aes(geometry=geometry),\n          color=\"black\",\n          show.legend=FALSE) +\n  ggflags::geom_flag(data=democracymap2 |&gt; \n                       filter(continent==\"Europe\",\n                              has_free_and_fair_election==TRUE),\n                     mapping=aes(y=lat,x=lon,country=tolower(iso2)),\n                     inherit.aes=FALSE) +\n  # gganimate allows you to use {closest_state} to fill in the transition label\n  labs(title= 'Year: {closest_state}') +\n  #metR scales\n  scale_x_longitude() +\n  scale_y_latitude() +\n  #gganimate transitions for the gif\n  transition_states(year) +\n  theme_bw() +\n  coord_sf(xlim=c(-20,40),\n           ylim=c(30,70),\n           default_crs=sf::st_crs(4326))\n\n#anim_save(filename=\"img/Europe.gif\",animation=Europe2)\n\n\n\n\n\nFree and Fair Elections in Europe\n\n\n\n\nCode in R\n#Africa\nAfrica2 &lt;- map |&gt; \n  filter(continent==\"Africa\") |&gt; \n  ggplot() +\n  geom_sf(mapping=aes(geometry=geometry),fill=\"white\",color=\"black\") +\n  geom_sf(data=democracymap2 |&gt; \n            filter(continent==\"Africa\"),\n          mapping=aes(geometry=geometry),color=\"black\",\n          show.legend=FALSE) +\n  scale_x_longitude() +\n  scale_y_latitude() +\n  ggflags::geom_flag(data=democracymap2 |&gt; \n                       filter(continent==\"Africa\",\n                              has_free_and_fair_election==TRUE),\n                     mapping=aes(y=lat,x=lon,\n                                 country=tolower(iso2)),\n                     inherit.aes=FALSE) +\n  labs(title = 'Year: {closest_state}') +\n  theme_bw() +\n  transition_states(year) +\n  coord_sf(default_crs=sf::st_crs(4326))\n\n#anim_save(filename=\"img/Africa.gif\",animation=Africa2)\n\n\n\n\n\nFree and Fair Elections in Africa"
  },
  {
    "objectID": "posts/2025-01-13-gganimate-ggflag/index.html#loading-and-exploring-a-tidy-tuesday-dataset",
    "href": "posts/2025-01-13-gganimate-ggflag/index.html#loading-and-exploring-a-tidy-tuesday-dataset",
    "title": "Using gganimate and ggflags to look at democratic progress",
    "section": "",
    "text": "One of my New Year’s resolutions was to become less of a lurker and more of a doer within the Tidy Tuesday community. There had been one dataset that I was super interested in exploring, based on Democracy and Dictatorship. Loaded the dataset and a few packages.\n\n\nCode in R\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\nlibrary(countrycode) #this package looks up ISO codes, which can be useful\nlibrary(ggflags) #pulls flags\nlibrary(gganimate) #animations\n\ndat &lt;- tidytuesdayR::tt_load(2024, week = 45)\ndemocracy &lt;- dat$democracy_data\n\nhead(democracy)\n\n\n# A tibble: 6 × 43\n  country_name country_code  year regime_category_index regime_category   \n  &lt;chr&gt;        &lt;chr&gt;        &lt;dbl&gt;                 &lt;dbl&gt; &lt;chr&gt;             \n1 Afghanistan  AFG           1950                     5 Royal dictatorship\n2 Afghanistan  AFG           1951                     5 Royal dictatorship\n3 Afghanistan  AFG           1952                     5 Royal dictatorship\n4 Afghanistan  AFG           1953                     5 Royal dictatorship\n5 Afghanistan  AFG           1954                     5 Royal dictatorship\n6 Afghanistan  AFG           1955                     5 Royal dictatorship\n# ℹ 38 more variables: is_monarchy &lt;lgl&gt;, is_commonwealth &lt;lgl&gt;,\n#   monarch_name &lt;chr&gt;, monarch_accession_year &lt;dbl&gt;, monarch_birthyear &lt;dbl&gt;,\n#   is_female_monarch &lt;lgl&gt;, is_democracy &lt;lgl&gt;, is_presidential &lt;lgl&gt;,\n#   president_name &lt;chr&gt;, president_accesion_year &lt;dbl&gt;,\n#   president_birthyear &lt;dbl&gt;, is_interim_phase &lt;lgl&gt;,\n#   is_female_president &lt;lgl&gt;, is_colony &lt;lgl&gt;, colony_of &lt;chr&gt;,\n#   colony_administrated_by &lt;chr&gt;, is_communist &lt;lgl&gt;, …\n\n\nThis dataset shows, for every year from 1950 to 2000, classifications for countries around the world. In the spirit of January 6th, I chose to focus on whether countries have free and fair elections, here shown as has_free_and_fair_election.\nIn the interest of this exploration, I’m not interested in colonies, which are shown as NA in the regime_category_index.\n\n\nCode in R\ndemocracy &lt;- democracy |&gt; \n  ## removing colonies as much as possible to get down to countries\n  filter(!is.na(regime_category_index),\n         ## British Virgin Islands oddly keeps showing up in spite of status as colony\n         country_code!=\"VGB\") \n\n\n\n\nMy first inclination in the dataset was to take out the countries that only had free and fair elections or a lack thereof, in order to understand places that had democratic progress and democratic backsliding. This required setting up a filter for this work. tabyl from the janitor package is well set up for this, as it will quickly come up with cross counts.\n\n\nCode in R\ndemocracyfilter &lt;- democracy |&gt; \n  janitor::tabyl(country_name,has_free_and_fair_election) |&gt; \n  filter(`TRUE` &gt; 0 & `FALSE` &gt; 0)\n\n\nThis gives a nice filter for this work. In order to use the ggflags package, you need for the countries to be spelled out in iso2c format. Fortunately, the amazing countrycodes package will do that for you, and in addition, it can provide the continent for you as well, for additional explorations.\n\n\nCode in R\ndemocraticchanges &lt;- democracy |&gt; \n  inner_join(democracyfilter) |&gt; \n  mutate(iso2=countrycode(country_name,\"country.name\",\"iso2c\"),\n         continent = countrycode(iso2, \"iso2c\", \"continent\")) |&gt; \n  arrange(continent,`FALSE`) |&gt; \n         mutate(country_name=fct_inorder(country_name))\n\n\nNow we are ready to plot this with the help of the ggflags package. Let’s look at Europe and Africa, two continents associated with democratic progress and backsliding.\nThere is one big issue - we would like for this to show up as continuous bars, which your typical geoms will not do. However, we can think of the bars as parts of a rectangle, that extend from the beginning to end of each year. If we factor the countries, we can then plot them and rename the y axis at the end.\n\n\nCode in R\n## Let's create the y-labels for later on\ny_lab &lt;- democraticchanges |&gt; \n  distinct(country_name,iso2,continent)  |&gt; \n  mutate(y_mid = as.numeric(country_name),\n         name=country_name)\n## For Africa\nAfrica &lt;- democraticchanges |&gt; \n  filter(continent==\"Africa\") |&gt; \n  ggplot(aes(xmin=year, #left boundary of the rectangle\n             xmax=year+1, #right boundary of the rectangle\n             ymin=as.numeric(country_name)-.3, #lower boundary of the rectangle\n             ymax=as.numeric(country_name)+.3, #upper boundary of the rectangle\n             fill=has_free_and_fair_election)) +\n  geom_rect() +\n  # now let's plot flags between the rectangles and the y axis\n  ggflags::geom_flag(data=y_lab |&gt; \n                       filter(continent==\"Africa\"),\n                     mapping=aes(y=y_mid,\n                                 country=tolower(iso2), #ggflags needs lowercase iso2 to work\n                                 x=1945),\n                     inherit.aes=FALSE) + #we want this to be individual to this layer\n                     #now to rename the y axis\n  scale_y_continuous(breaks=y_lab$y_mid,labels=y_lab$country_name) +\n  theme_minimal() +\n  theme(legend.position=\"bottom\",\n        legend.text=element_text(size=7),\n        legend.title=element_text(size=7)) +\n  labs(x=\"\",\n       y=\"\",\n       fill=\"Has Free and Fair Elections\") +\n  scale_fill_brewer(palette=\"Set1\") +\n  facet_wrap(~continent,ncol=1,scales=\"free\",strip.position=\"right\")\n\nEurope &lt;- democraticchanges |&gt; \n  filter(continent==\"Europe\") |&gt; \n  ggplot(aes(xmin=year,\n             xmax=year+1,\n             ymin=as.numeric(country_name)-.3,\n             ymax=as.numeric(country_name)+.3,\n             fill=has_free_and_fair_election)) +\n  geom_rect() +\n  ggflags::geom_flag(data=y_lab |&gt; \n                       filter(continent==\"Europe\"),\n                     mapping=aes(y=y_mid,country=tolower(iso2),x=1945),inherit.aes=FALSE) +\n  scale_y_continuous(breaks=y_lab$y_mid,labels=y_lab$country_name) +\n  theme_minimal() +\n  theme(legend.position=\"bottom\",\n        legend.text=element_text(size=7),\n        legend.title=element_text(size=7)) +\n  labs(x=\"\",\n       y=\"\",\n       fill=\"Has Free and Fair Elections\") +\n  scale_fill_brewer(palette=\"Set1\") +\n  facet_wrap(~continent,ncol=1,scales=\"free\",strip.position=\"right\")\n\n## Let's take advantage of patchwork to plot these graphs next to each other with a common legend\nlibrary(patchwork)\nEurope + Africa + plot_layout(guides = 'collect') & theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\nThis is fun! Let’s make a map and animate it.\n\n\n\nOne can see at a glance that, in Europe, there appears to be a democratic progression. Similarly, in Africa, there is a progression, but there is also backsliding. It would also be really useful to see this as a map - moreover, it would be really interesting to see as an animated map.\nrnaturalearth is a package that allows you to easily download map borders. Patrice Ferlet keeps a dataset of the centroid for countries that we can plot the flags on as well.\n\n\nCode in R\nlibrary(rnaturalearth)\n\nworld &lt;- ne_countries(type=\"countries\",returnclass=\"sf\")\n\ncoord &lt;- read_csv(\"https://gist.github.com/metal3d/5b925077e66194551df949de64e910f6/raw/c5f20a037409d96958553e2eb6b8251265c6fd63/country-coord.csv\") |&gt; \n  mutate(`Alpha-2 code`=replace_na(`Alpha-2 code`,\"NA\")) |&gt; \n  rename(code=`Alpha-2 code`,\n         lat=`Latitude (average)`,\n         lon=`Longitude (average)`)\n\n\nNow let’s take the democracy dataset from earlier, and left_join the dataset to the lat/long dataset as well as the world dataset\n\n\nCode in R\ndemocracymap &lt;- democracy |&gt; \n  mutate(iso2=countrycode(country_name,\"country.name\",\"iso2c\"),\n         continent = countrycode(iso2, \"iso2c\", \"continent\")) |&gt; \n  select(country_name,year,has_free_and_fair_election,iso2,continent) |&gt; \n  left_join(coord |&gt;\n              select(code,lat,lon),by=c(\"iso2\"=\"code\"))\n\ndemocracymap &lt;- democracymap |&gt; \n  select(country_name,year,has_free_and_fair_election,iso2,lat,lon) |&gt; \n  left_join(world, by=c(\"iso2\"=\"iso_a2_eh\")) |&gt; \n  filter(!is.na(geometry)) |&gt; \n  mutate(year=as.integer(year)) #this is necessary for the animation to progress frame by frame\n\n\nWe build this layer by layer. We want a base map of current boundaries, so we can take the current dataset and bring in one year’s worth of data.\n\n\nCode in R\nmap &lt;- democracymap |&gt; \n  filter(year==2020, !is.na(geometry)) |&gt; \n  select(-year)\n\nmap |&gt; \n  ggplot() + geom_sf(aes(geometry=geometry))\n\n\n\n\n\nWorld Map\n\n\n\n\nThen we can layer this map easily. Notice that the latitude and longitude signs are not typical of a map - the excellent metR package includes helpful themes and scales for meteorological data, which applies to maps as well!\n\n\nCode in R\ndemocracymap2 &lt;- democracymap |&gt; \n  filter(has_free_and_fair_election==TRUE)\n\nlibrary(metR)\n\nmap |&gt; \n  ggplot() +\n  geom_sf(mapping=aes(geometry=geometry),fill=\"white\",color=\"black\") +\n  geom_sf(data=democracymap2,\n          mapping=aes(geometry=geometry),color=NA,fill=\"blue\",\n          show.legend=FALSE)+\n  scale_x_longitude() +\n  scale_y_latitude() +\n  facet_wrap(~year) +\n  theme_bw() +\n  theme(axis.text=element_blank(),\n        axis.ticks=element_blank(),\n        strip.text=element_text(size=8,\n                                margin = margin(0,0,0,0, \"cm\")))\n\n\n\n\n\nA facet of the world\n\n\n\n\nThis map is a bit overwhelming, let’s use gganimate and focus on Europe and Africa. Comments below to walk through the European one. Because it’s tough to render, I saved it locally and then loaded it up on the website. Hooray!\n\n\nCode in R\n#Europe\n#First a base layer\nEurope2 &lt;- map |&gt; \n  filter(continent==\"Europe\") |&gt; \n  ggplot() +\n  # note that fill is the inside and color is the border in geom_sf\n  geom_sf(mapping=aes(geometry=geometry),fill=\"white\",color=\"black\") +\n#Then the democracy data\n  geom_sf(data=democracymap2 |&gt; \n            filter(continent==\"Europe\"),\n          mapping=aes(geometry=geometry),\n          color=\"black\",\n          show.legend=FALSE) +\n  ggflags::geom_flag(data=democracymap2 |&gt; \n                       filter(continent==\"Europe\",\n                              has_free_and_fair_election==TRUE),\n                     mapping=aes(y=lat,x=lon,country=tolower(iso2)),\n                     inherit.aes=FALSE) +\n  # gganimate allows you to use {closest_state} to fill in the transition label\n  labs(title= 'Year: {closest_state}') +\n  #metR scales\n  scale_x_longitude() +\n  scale_y_latitude() +\n  #gganimate transitions for the gif\n  transition_states(year) +\n  theme_bw() +\n  coord_sf(xlim=c(-20,40),\n           ylim=c(30,70),\n           default_crs=sf::st_crs(4326))\n\n#anim_save(filename=\"img/Europe.gif\",animation=Europe2)\n\n\n\n\n\nFree and Fair Elections in Europe\n\n\n\n\nCode in R\n#Africa\nAfrica2 &lt;- map |&gt; \n  filter(continent==\"Africa\") |&gt; \n  ggplot() +\n  geom_sf(mapping=aes(geometry=geometry),fill=\"white\",color=\"black\") +\n  geom_sf(data=democracymap2 |&gt; \n            filter(continent==\"Africa\"),\n          mapping=aes(geometry=geometry),color=\"black\",\n          show.legend=FALSE) +\n  scale_x_longitude() +\n  scale_y_latitude() +\n  ggflags::geom_flag(data=democracymap2 |&gt; \n                       filter(continent==\"Africa\",\n                              has_free_and_fair_election==TRUE),\n                     mapping=aes(y=lat,x=lon,\n                                 country=tolower(iso2)),\n                     inherit.aes=FALSE) +\n  labs(title = 'Year: {closest_state}') +\n  theme_bw() +\n  transition_states(year) +\n  coord_sf(default_crs=sf::st_crs(4326))\n\n#anim_save(filename=\"img/Africa.gif\",animation=Africa2)\n\n\n\n\n\nFree and Fair Elections in Africa"
  },
  {
    "objectID": "posts/2025-01-17-fuzzyjoin-in-action/index.html",
    "href": "posts/2025-01-17-fuzzyjoin-in-action/index.html",
    "title": "Using fuzzyjoin to work with NCES data",
    "section": "",
    "text": "Like families, tidy datasets are all alike but every messy dataset is messy in its own way.\n- Hadley Wickham\n\nWe often work with datasets where there is a unique identifier that can be used to link or filter the data, typically involving some type of a join.\nHowever, sometimes the identifiers that we wish to use to join are near matches. For instance, maybe you are joining a dataset by names, where one dataset has John, and the dataset you are joining has john. Or maybe there are text entry errors and it is instead Jon.\nWhat you need is a way to join data that is a little bit fuzzy. Enter David Robinson’s excellent fuzzyjoin package.\n\n\nThere are 20 schools listed in the public school database for the National Center for Education Statistics in the Virgin Islands. I’ve downloaded the dataset and you can pull it from my github repo through the code below. A scrollable kableExtra table to explore below (disabling a lot of features just to see the table):\n\n\nCode in R\nlibrary(tidyverse)\nlibrary(fuzzyjoin)\nlibrary(kableExtra)\nVI &lt;- read_csv(\"https://github.com/drjohnrussell/drjohnrussell.github.io/raw/refs/heads/master/posts/2025-01-17-fuzzyjoin-in-action/data/VIschools.csv\")\n\nVI |&gt; \n  kbl() |&gt; \n  kable_paper() |&gt; ##nice theme\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) |&gt; \n  scroll_box(height = \"200px\") ##adds scrolling\n\n\n\n\nPublic Schools of Virgin Islands\n\n\nschoolname\nnces\ndistrict\naddress\nstate\nlow_grade\nhi_grade\ntotal\n\n\n\n\nAlfredo Andrews Elementary School\n780000200002\nSaint Croix School District\nRFD 1 KINGSHILL\nVI\nPK\n06\n495\n\n\nClaude O. Markoe Elementary School\n780000200006\nSaint Croix School District\nPLOTS 71 75 MARS HILL\nVI\nPK\n06\n403\n\n\nEulalie Rivera\n780000200011\nSaint Croix School District\nROUTE 1 GROVE PLACE\nVI\nPK\n08\n645\n\n\nSt. Croix Educational Complex High School\n780000200013\nSaint Croix School District\nRR2 KINGSHILL\nVI\n09\n12\n893\n\n\nJuanita Gardine\n780000200021\nSaint Croix School District\nESTATE RICHMOND\nVI\nPK\n08\n305\n\n\nLew Muckle Elementary School\n780000200023\nSaint Croix School District\n317 SION FARM\nVI\nPK\n06\n339\n\n\nPearl B. Larsen\n780000200028\nSaint Croix School District\nESTATE ST PETERS\nVI\nPK\n08\n432\n\n\nRicardo Richards Elementary School\n780000200029\nSaint Croix School District\n491 BARREN SPOT\nVI\nPK\n06\n392\n\n\nSt. Croix Central High School\n780000200030\nSaint Croix School District\nRSD 2 KINGSHILL\nVI\n09\n12\n717\n\n\nJohn H. Woodson Junior High School\n780000200037\nSaint Croix School District\nRURAL ROUTE 1 KINGSHILL\nVI\n07\n08\n461\n\n\nCharlotte Amalie High School\n780003000005\nSaint Thomas - Saint John School District\n8 and 9 ESTATE THOMAS\nVI\n09\n12\n1076\n\n\nIvanna Eudora Kean High School\n780003000015\nSaint Thomas - Saint John School District\n1 and 2 ESTate NAZARETH\nVI\n09\n12\n738\n\n\nJane E. Tuitt Elementary School\n780003000018\nSaint Thomas - Saint John School District\n19 LEVOKI STRAEDE\nVI\nKG\n04\n154\n\n\nJoseph Gomez Elementary School\n780003000019\nSaint Thomas - Saint John School District\n142 ANNAS RETREAT\nVI\nPK\n05\n462\n\n\nJoseph Sibilly Elementary School\n780003000020\nSaint Thomas - Saint John School District\n14 15 16 ESTATE ELIZABETH\nVI\nPK\n05\n226\n\n\nJulius E. Sprauve School\n780003000022\nSaint Thomas - Saint John School District\n14 18 ESTATE ENIGHED\nVI\nPK\n08\n225\n\n\nLockhart Elementary School\n780003000024\nSaint Thomas - Saint John School District\n41 ESTATE THOMAS\nVI\nKG\n08\n977\n\n\nUlla F. Muller Elementary School\n780003000026\nSaint Thomas - Saint John School District\n7B ESTATE CONTANT\nVI\nPK\n05\n401\n\n\nYvonne E. Milliner-Bowsky Elementary School\n780003000027\nSaint Thomas - Saint John School District\n15B and 16 ESTATE MANDAHL\nVI\nPK\n05\n433\n\n\nBertha C. Boschulte Middle School\n780003000034\nSaint Thomas - Saint John School District\n9 1 and 12A BOVONI\nVI\n06\n08\n538\n\n\n\n\n\n\n\nLet’s say we have a dataset with the following names of schools, and we want to pull in information from NCES.\n\n\nCode in R\nsample &lt;- read_csv(\"https://github.com/drjohnrussell/drjohnrussell.github.io/raw/refs/heads/master/posts/2025-01-17-fuzzyjoin-in-action/data/sample.csv\")\n\nsample |&gt; \n  kbl() |&gt; \n  kable_paper()\n\n\n\nDataset to join\n\n\nschoolname\nstate\n\n\n\n\neulalie rivera\nVI\n\n\nJoseph Elementary School\nVI\n\n\nAlfredo Andrews Elementary School\nNY\n\n\n\n\n\n\n\nEnter the fuzzyjoin package, which allows the data to be messy in many ways, depending on what you need. Some of the ways to join outlined in the package are as follows:\n\ndifference_join - joins that are numeric and within a specified distance\ngeo_join - joins that use distances based on latitude and longitude\nregex_join - joins that look for common regex patterns (text and position)\nstringdist_join - joins that take into account small differences in the string\n\nLet’s focus on stringdist_join for special case uses.\n\n\n\nJoins that ignore case, where you don’t have to mutate using something like the stringr str_to_lower on the data to change it is a big win. We can use it to match eulalie rivera.\nThis is what would happen as is:\n\n\nCode in R\nsample[1,1] |&gt; \n  inner_join(VI,by=c(\"schoolname\")) |&gt; \n  kbl() |&gt; \n  kable_paper()\n\n\n\nAn empty inner join\n\n\nschoolname\nnces\ndistrict\naddress\nstate\nlow_grade\nhi_grade\ntotal\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn the other hand, we can use the stringdist_join and set ignore_case to equal TRUE.\n\n\nCode in R\nsample[1,1] |&gt; \n  stringdist_join(VI,\n                  by=c(\"schoolname\"),\n                  max_dist=0,\n                  mode=\"inner\",\n                  ignore_case=TRUE) |&gt; \n  kbl() |&gt; \n  kable_paper()\n\n\n\nA successful join\n\n\nschoolname.x\nschoolname.y\nnces\ndistrict\naddress\nstate\nlow_grade\nhi_grade\ntotal\n\n\n\n\neulalie rivera\nEulalie Rivera\n780000200011\nSaint Croix School District\nROUTE 1 GROVE PLACE\nVI\nPK\n08\n645\n\n\n\n\n\n\n\n\n\n\nThe way that I’ve taken advantage of this is in dealing with typos or data where someone may have subtly different names for a school (e.g., one has the word school while the other drops it). What is nice about the fuzzyjoin package is that you can do the join. What is less nice is that it requires you to do a line check afterwards, especially when you are loose with the distances.\nLet’s look at the second row, Joseph Elementary School, and have a maximum distance of 8.\n\n\nCode in R\nsample[2,1] |&gt; \n  stringdist_join(VI,\n                   by=\"schoolname\",\n                   max_dist=8,\n                   mode=\"inner\",\n                   ignore_case=TRUE,\n                  distance_col=\"stringdistance\") |&gt; \n  kbl() |&gt; \n  kable_paper()\n\n\n\nMultiple rows loosely match\n\n\nschoolname.x\nschoolname.y\nnces\ndistrict\naddress\nstate\nlow_grade\nhi_grade\ntotal\nstringdistance\n\n\n\n\nJoseph Elementary School\nJoseph Gomez Elementary School\n7.80003e+11\nSaint Thomas - Saint John School District\n142 ANNAS RETREAT\nVI\nPK\n05\n462\n6\n\n\nJoseph Elementary School\nJoseph Sibilly Elementary School\n7.80003e+11\nSaint Thomas - Saint John School District\n14 15 16 ESTATE ELIZABETH\nVI\nPK\n05\n226\n8\n\n\nJoseph Elementary School\nLockhart Elementary School\n7.80003e+11\nSaint Thomas - Saint John School District\n41 ESTATE THOMAS\nVI\nKG\n08\n977\n7\n\n\n\n\n\n\n\nYou can see the power, and the danger, of the fuzzyjoin package here. It’s amazing that it picks up the two schools that also have Joseph in their name, but it also suggests that you could change a few letters in the beginning and form the name of another school.\nWhen we used fuzzyjoin, we would arrange the data by the school name and then the distance_col variable so that we could easily do a line check and choose the best match (if available).\n\n\n\nAs a side note, it is nice to use the fuzzyjoin package for seeing errors in multiple columns. Here we can see how it works with the third row of the dataset.\n\n\nCode in R\nsample[3,] |&gt; \n  stringdist_join(VI,\n                  by=c(\"schoolname\",\"state\"),\n                  mode=\"inner\",\n                  max_dist = 4,\n                  ignore_case=TRUE,\n                  distance_col=\"stringdistance\") |&gt; \n  kbl() |&gt; \n  kable_paper()\n\n\n\n\n\nschoolname.x\nstate.x\nschoolname.y\nnces\ndistrict\naddress\nstate.y\nlow_grade\nhi_grade\ntotal\nschoolname.stringdistance\nstate.stringdistance\nstringdistance\n\n\n\n\nAlfredo Andrews Elementary School\nNY\nAlfredo Andrews Elementary School\n780000200002\nSaint Croix School District\nRFD 1 KINGSHILL\nVI\nPK\n06\n495\n0\n2\nNA\n\n\n\n\n\n\n\nWhat is nice about this is that, in review, you can see easily through the distance_col variable where the changes were found. For instance, maybe you want the join to include state, but you want to exclude this example because you know that schools in other states may have the same name; it would just be as simple as adding a filter at the end to take out stringdist.state &gt; 0.\n\n\nOthers have used fuzzyjoin to great effect - I am inspired reading this vignette in particular on geo_joins"
  },
  {
    "objectID": "posts/2025-01-17-fuzzyjoin-in-action/index.html#introducing-an-example---schools-in-the-virgin-islands",
    "href": "posts/2025-01-17-fuzzyjoin-in-action/index.html#introducing-an-example---schools-in-the-virgin-islands",
    "title": "Using fuzzyjoin to work with NCES data",
    "section": "",
    "text": "There are 20 schools listed in the public school database for the National Center for Education Statistics in the Virgin Islands. I’ve downloaded the dataset and you can pull it from my github repo through the code below. A scrollable kableExtra table to explore below (disabling a lot of features just to see the table):\n\n\nCode in R\nlibrary(tidyverse)\nlibrary(fuzzyjoin)\nlibrary(kableExtra)\nVI &lt;- read_csv(\"https://github.com/drjohnrussell/drjohnrussell.github.io/raw/refs/heads/master/posts/2025-01-17-fuzzyjoin-in-action/data/VIschools.csv\")\n\nVI |&gt; \n  kbl() |&gt; \n  kable_paper() |&gt; ##nice theme\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) |&gt; \n  scroll_box(height = \"200px\") ##adds scrolling\n\n\n\n\nPublic Schools of Virgin Islands\n\n\nschoolname\nnces\ndistrict\naddress\nstate\nlow_grade\nhi_grade\ntotal\n\n\n\n\nAlfredo Andrews Elementary School\n780000200002\nSaint Croix School District\nRFD 1 KINGSHILL\nVI\nPK\n06\n495\n\n\nClaude O. Markoe Elementary School\n780000200006\nSaint Croix School District\nPLOTS 71 75 MARS HILL\nVI\nPK\n06\n403\n\n\nEulalie Rivera\n780000200011\nSaint Croix School District\nROUTE 1 GROVE PLACE\nVI\nPK\n08\n645\n\n\nSt. Croix Educational Complex High School\n780000200013\nSaint Croix School District\nRR2 KINGSHILL\nVI\n09\n12\n893\n\n\nJuanita Gardine\n780000200021\nSaint Croix School District\nESTATE RICHMOND\nVI\nPK\n08\n305\n\n\nLew Muckle Elementary School\n780000200023\nSaint Croix School District\n317 SION FARM\nVI\nPK\n06\n339\n\n\nPearl B. Larsen\n780000200028\nSaint Croix School District\nESTATE ST PETERS\nVI\nPK\n08\n432\n\n\nRicardo Richards Elementary School\n780000200029\nSaint Croix School District\n491 BARREN SPOT\nVI\nPK\n06\n392\n\n\nSt. Croix Central High School\n780000200030\nSaint Croix School District\nRSD 2 KINGSHILL\nVI\n09\n12\n717\n\n\nJohn H. Woodson Junior High School\n780000200037\nSaint Croix School District\nRURAL ROUTE 1 KINGSHILL\nVI\n07\n08\n461\n\n\nCharlotte Amalie High School\n780003000005\nSaint Thomas - Saint John School District\n8 and 9 ESTATE THOMAS\nVI\n09\n12\n1076\n\n\nIvanna Eudora Kean High School\n780003000015\nSaint Thomas - Saint John School District\n1 and 2 ESTate NAZARETH\nVI\n09\n12\n738\n\n\nJane E. Tuitt Elementary School\n780003000018\nSaint Thomas - Saint John School District\n19 LEVOKI STRAEDE\nVI\nKG\n04\n154\n\n\nJoseph Gomez Elementary School\n780003000019\nSaint Thomas - Saint John School District\n142 ANNAS RETREAT\nVI\nPK\n05\n462\n\n\nJoseph Sibilly Elementary School\n780003000020\nSaint Thomas - Saint John School District\n14 15 16 ESTATE ELIZABETH\nVI\nPK\n05\n226\n\n\nJulius E. Sprauve School\n780003000022\nSaint Thomas - Saint John School District\n14 18 ESTATE ENIGHED\nVI\nPK\n08\n225\n\n\nLockhart Elementary School\n780003000024\nSaint Thomas - Saint John School District\n41 ESTATE THOMAS\nVI\nKG\n08\n977\n\n\nUlla F. Muller Elementary School\n780003000026\nSaint Thomas - Saint John School District\n7B ESTATE CONTANT\nVI\nPK\n05\n401\n\n\nYvonne E. Milliner-Bowsky Elementary School\n780003000027\nSaint Thomas - Saint John School District\n15B and 16 ESTATE MANDAHL\nVI\nPK\n05\n433\n\n\nBertha C. Boschulte Middle School\n780003000034\nSaint Thomas - Saint John School District\n9 1 and 12A BOVONI\nVI\n06\n08\n538\n\n\n\n\n\n\n\nLet’s say we have a dataset with the following names of schools, and we want to pull in information from NCES.\n\n\nCode in R\nsample &lt;- read_csv(\"https://github.com/drjohnrussell/drjohnrussell.github.io/raw/refs/heads/master/posts/2025-01-17-fuzzyjoin-in-action/data/sample.csv\")\n\nsample |&gt; \n  kbl() |&gt; \n  kable_paper()\n\n\n\nDataset to join\n\n\nschoolname\nstate\n\n\n\n\neulalie rivera\nVI\n\n\nJoseph Elementary School\nVI\n\n\nAlfredo Andrews Elementary School\nNY\n\n\n\n\n\n\n\nEnter the fuzzyjoin package, which allows the data to be messy in many ways, depending on what you need. Some of the ways to join outlined in the package are as follows:\n\ndifference_join - joins that are numeric and within a specified distance\ngeo_join - joins that use distances based on latitude and longitude\nregex_join - joins that look for common regex patterns (text and position)\nstringdist_join - joins that take into account small differences in the string\n\nLet’s focus on stringdist_join for special case uses."
  },
  {
    "objectID": "posts/2025-01-17-fuzzyjoin-in-action/index.html#joins-that-ignore-case",
    "href": "posts/2025-01-17-fuzzyjoin-in-action/index.html#joins-that-ignore-case",
    "title": "Using fuzzyjoin to work with NCES data",
    "section": "",
    "text": "Joins that ignore case, where you don’t have to mutate using something like the stringr str_to_lower on the data to change it is a big win. We can use it to match eulalie rivera.\nThis is what would happen as is:\n\n\nCode in R\nsample[1,1] |&gt; \n  inner_join(VI,by=c(\"schoolname\")) |&gt; \n  kbl() |&gt; \n  kable_paper()\n\n\n\nAn empty inner join\n\n\nschoolname\nnces\ndistrict\naddress\nstate\nlow_grade\nhi_grade\ntotal\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn the other hand, we can use the stringdist_join and set ignore_case to equal TRUE.\n\n\nCode in R\nsample[1,1] |&gt; \n  stringdist_join(VI,\n                  by=c(\"schoolname\"),\n                  max_dist=0,\n                  mode=\"inner\",\n                  ignore_case=TRUE) |&gt; \n  kbl() |&gt; \n  kable_paper()\n\n\n\nA successful join\n\n\nschoolname.x\nschoolname.y\nnces\ndistrict\naddress\nstate\nlow_grade\nhi_grade\ntotal\n\n\n\n\neulalie rivera\nEulalie Rivera\n780000200011\nSaint Croix School District\nROUTE 1 GROVE PLACE\nVI\nPK\n08\n645"
  },
  {
    "objectID": "posts/2025-01-17-fuzzyjoin-in-action/index.html#joins-that-take-advantage-of-string-distance",
    "href": "posts/2025-01-17-fuzzyjoin-in-action/index.html#joins-that-take-advantage-of-string-distance",
    "title": "Using fuzzyjoin to work with NCES data",
    "section": "",
    "text": "The way that I’ve taken advantage of this is in dealing with typos or data where someone may have subtly different names for a school (e.g., one has the word school while the other drops it). What is nice about the fuzzyjoin package is that you can do the join. What is less nice is that it requires you to do a line check afterwards, especially when you are loose with the distances.\nLet’s look at the second row, Joseph Elementary School, and have a maximum distance of 8.\n\n\nCode in R\nsample[2,1] |&gt; \n  stringdist_join(VI,\n                   by=\"schoolname\",\n                   max_dist=8,\n                   mode=\"inner\",\n                   ignore_case=TRUE,\n                  distance_col=\"stringdistance\") |&gt; \n  kbl() |&gt; \n  kable_paper()\n\n\n\nMultiple rows loosely match\n\n\nschoolname.x\nschoolname.y\nnces\ndistrict\naddress\nstate\nlow_grade\nhi_grade\ntotal\nstringdistance\n\n\n\n\nJoseph Elementary School\nJoseph Gomez Elementary School\n7.80003e+11\nSaint Thomas - Saint John School District\n142 ANNAS RETREAT\nVI\nPK\n05\n462\n6\n\n\nJoseph Elementary School\nJoseph Sibilly Elementary School\n7.80003e+11\nSaint Thomas - Saint John School District\n14 15 16 ESTATE ELIZABETH\nVI\nPK\n05\n226\n8\n\n\nJoseph Elementary School\nLockhart Elementary School\n7.80003e+11\nSaint Thomas - Saint John School District\n41 ESTATE THOMAS\nVI\nKG\n08\n977\n7\n\n\n\n\n\n\n\nYou can see the power, and the danger, of the fuzzyjoin package here. It’s amazing that it picks up the two schools that also have Joseph in their name, but it also suggests that you could change a few letters in the beginning and form the name of another school.\nWhen we used fuzzyjoin, we would arrange the data by the school name and then the distance_col variable so that we could easily do a line check and choose the best match (if available)."
  },
  {
    "objectID": "posts/2025-01-17-fuzzyjoin-in-action/index.html#matching-off-of-multiple-columns",
    "href": "posts/2025-01-17-fuzzyjoin-in-action/index.html#matching-off-of-multiple-columns",
    "title": "Using fuzzyjoin to work with NCES data",
    "section": "",
    "text": "As a side note, it is nice to use the fuzzyjoin package for seeing errors in multiple columns. Here we can see how it works with the third row of the dataset.\n\n\nCode in R\nsample[3,] |&gt; \n  stringdist_join(VI,\n                  by=c(\"schoolname\",\"state\"),\n                  mode=\"inner\",\n                  max_dist = 4,\n                  ignore_case=TRUE,\n                  distance_col=\"stringdistance\") |&gt; \n  kbl() |&gt; \n  kable_paper()\n\n\n\n\n\nschoolname.x\nstate.x\nschoolname.y\nnces\ndistrict\naddress\nstate.y\nlow_grade\nhi_grade\ntotal\nschoolname.stringdistance\nstate.stringdistance\nstringdistance\n\n\n\n\nAlfredo Andrews Elementary School\nNY\nAlfredo Andrews Elementary School\n780000200002\nSaint Croix School District\nRFD 1 KINGSHILL\nVI\nPK\n06\n495\n0\n2\nNA\n\n\n\n\n\n\n\nWhat is nice about this is that, in review, you can see easily through the distance_col variable where the changes were found. For instance, maybe you want the join to include state, but you want to exclude this example because you know that schools in other states may have the same name; it would just be as simple as adding a filter at the end to take out stringdist.state &gt; 0.\n\n\nOthers have used fuzzyjoin to great effect - I am inspired reading this vignette in particular on geo_joins"
  },
  {
    "objectID": "posts/2024-01-04-Map1-2024/index.html",
    "href": "posts/2024-01-04-Map1-2024/index.html",
    "title": "Getting back into blogging",
    "section": "",
    "text": "library(RSocrata)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(sf)\n\nLinking to GEOS 3.12.2, GDAL 3.9.3, PROJ 9.4.1; sf_use_s2() is TRUE\n\nlibrary(jsonlite)\n\n\nAttaching package: 'jsonlite'\n\nThe following object is masked from 'package:purrr':\n\n    flatten\n\ndata &lt;- read_json(\"https://www.nycgovparks.org/bigapps/DPR_Playgrounds_001.json\", simplifyVector = TRUE)\n\n\n\n\nCitationBibTeX citation:@online{russell2024,\n  author = {Russell, John},\n  title = {Getting Back into Blogging},\n  date = {2024-12-28},\n  url = {https://drjohnrussell.github.io/posts/2024-12-28-getting-back-online/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRussell, John. 2024. “Getting Back into Blogging.” December\n28, 2024. https://drjohnrussell.github.io/posts/2024-12-28-getting-back-online/."
  },
  {
    "objectID": "posts/2025-01-30-plotting-sleep-intervals/index.html",
    "href": "posts/2025-01-30-plotting-sleep-intervals/index.html",
    "title": "Using fuzzyjoin to work with NCES data",
    "section": "",
    "text": "Battling first child amnesia\nI am a father of two sons; one 4.5 years old, and the other is but a few months. This may seem weird, but even though I went through everything with my first son… I have complete amnesia about what was normal, what napping schedules were like, and such-like at this age.\nFortunately, we used a baby tracker, which allowed me to export a csv. What a golden opportunity for some data visualization!\nLet’s just load up the library and take a look…\n\n\nCode in R\nlibrary(tidyverse)\n\n\nchild &lt;- read_csv(\"https://github.com/drjohnrussell/drjohnrussell.github.io/raw/refs/heads/master/posts/2025-01-30-plotting-sleep-intervals/data/baby.csv\")\n\nhead(child)\n\n\n# A tibble: 6 × 3\n  Baby       Time              `Duration (min)`\n  &lt;chr&gt;      &lt;chr&gt;                        &lt;dbl&gt;\n1 First-Born 10/23/20 4:30 AM                60\n2 First-Born 10/23/20 6:00 AM                55\n3 First-Born 10/23/20 8:31 AM                39\n4 First-Born 10/23/20 11:13 AM               28\n5 First-Born 10/23/20 3:49 PM                14\n6 First-Born 10/23/20 7:16 PM               298\n\n\n|&gt; mutate(starttime=mdy_hm(Time), endtime=starttime+minutes(Duration (min))) ## separate the ones that go over multiple days\nViggo &lt;- read_csv(“Viggo_sleep.csv”) |&gt; mutate(starttime=mdy_hm(Time), endtime=starttime+minutes(Duration (min)))\nElginmultiple &lt;- Elgin |&gt; filter(day(starttime)!=day(endtime))\nViggomultiple &lt;- Viggo |&gt; filter(day(starttime)!=day(endtime))\nElgin1 &lt;- Elginmultiple |&gt; mutate(endtime=make_datetime(year(starttime),month(starttime),day(starttime),hour=23,min=59,sec=0)) Elgin2 &lt;- Elginmultiple |&gt; mutate(starttime=make_datetime(year(endtime),month(endtime),day(endtime),hour=0,min=0))\nViggo1 &lt;- Viggomultiple |&gt; mutate(endtime=make_datetime(year(starttime),month(starttime),day(starttime),hour=23,min=59,sec=0)) Viggo2 &lt;- Viggomultiple |&gt; mutate(starttime=make_datetime(year(endtime),month(endtime),day(endtime),hour=0,min=0))\nbirth &lt;- mdy(“05-30-20”) birthViggo &lt;- mdy(“07-28-24”)\nElgin &lt;- Elgin |&gt; filter(day(starttime)==day(endtime)) |&gt; bind_rows(Elgin1,Elgin2)\nElgin2 &lt;- Elgin |&gt; mutate(daysold=floor(difftime(starttime,birth,units=“weeks”)), dayweek=wday(starttime,label=TRUE,abbr=FALSE,week_start=7), starthour=hm(paste0(hour(starttime),“:”,minute(starttime))), endhour=hm(paste0(hour(endtime),“:”,minute(endtime))))\nViggo &lt;- Viggo |&gt; filter(day(starttime)==day(endtime)) |&gt; bind_rows(Viggo1,Viggo2)\nViggo2 &lt;- Viggo |&gt; mutate(daysold=floor(difftime(starttime,birthViggo,units=“weeks”)), dayweek=wday(starttime,label=TRUE,abbr=FALSE,week_start=7), starthour=hm(paste0(hour(starttime),“:”,minute(starttime))), endhour=hm(paste0(hour(endtime),“:”,minute(endtime))))\nnursing &lt;- read_csv(“Elgin Russell_nursing.csv”) |&gt; mutate(Time=mdy_hm(Time)) |&gt; select(Time)\nmilk &lt;- read_csv(“Elgin Russell_expressed.csv”) |&gt; mutate(Time=mdy_hm(Time)) |&gt; select(Time) |&gt; bind_rows(nursing)\nElginmilk &lt;- milk |&gt; mutate(daysold=floor(difftime(Time,birth,units=“weeks”)), dayweek=wday(Time,label=TRUE,abbr=FALSE,week_start=7), hour=hm(paste0(hour(Time),“:”,minute(Time)))) |&gt; filter(daysold&gt;20, daysold&lt;30)\nBREAKS &lt;- c(0:12)*7200\nElgin2 |&gt; filter(daysold&gt;20, daysold&lt;30) |&gt; ggplot() + geom_rect(mapping=aes(xmin=as.numeric(dayweek)-.45, xmax=as.numeric(dayweek)+.45, ymin=starthour, ymax=endhour),fill=“blue”, alpha=.5) + geom_rect(data=Viggo2 |&gt; filter(daysold&gt;20), mapping=aes(xmin=as.numeric(dayweek)-.45, xmax=as.numeric(dayweek)+.45, ymin=starthour, ymax=endhour),fill=“green”, alpha=.5) + facet_wrap(~daysold) + geom_point(data=Elginmilk, mapping=aes(x=as.numeric(dayweek), y=hour),color=“pink”) + scale_y_time(breaks=BREAKS) + scale_x_continuous(breaks=seq_along(levels(Elgin2\\(dayweek)), labels=levels(Elgin2\\)dayweek)) + labs(x=““,y=”“)\nround(difftime(today(),mdy(“07-28-24”),units=“weeks”),0)\nggsave(“Elgin.svg”,width=11,height=18,units=“in”)\n\n\n\n\nCitationBibTeX citation:@online{russell2025,\n  author = {Russell, John},\n  title = {Using Fuzzyjoin to Work with {NCES} Data},\n  date = {2025-01-17},\n  url = {https://drjohnrussell.github.io/posts/2025-01-17-fuzzyjoin-in-action/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRussell, John. 2025. “Using Fuzzyjoin to Work with NCES\nData.” January 17, 2025. https://drjohnrussell.github.io/posts/2025-01-17-fuzzyjoin-in-action/."
  },
  {
    "objectID": "posts/2025-02-04-plotting-sleep-intervals/index.html",
    "href": "posts/2025-02-04-plotting-sleep-intervals/index.html",
    "title": "Working with Time to battle Baby Amnesia",
    "section": "",
    "text": "I am a father of two sons; one 4.5 years old, and the other is but a few months. This may seem weird, but even though I went through everything with my first son… I have complete amnesia about what was normal, what napping schedules were like, and such-like at this age.\nFortunately, we used a baby tracker, which allowed me to export a csv. What a golden opportunity for some data visualization!\nLet’s just load up tidyverse and take a look…\n\n\nCode in R\nlibrary(tidyverse)\n\n\nchild &lt;- read_csv(\"https://github.com/drjohnrussell/drjohnrussell.github.io/raw/refs/heads/master/posts/2025-01-30-plotting-sleep-intervals/data/baby.csv\")\n\nhead(child)\n\n\n# A tibble: 6 × 3\n  Baby       Time              `Duration (min)`\n  &lt;chr&gt;      &lt;chr&gt;                        &lt;dbl&gt;\n1 First-Born 10/23/20 4:30 AM                60\n2 First-Born 10/23/20 6:00 AM                55\n3 First-Born 10/23/20 8:31 AM                39\n4 First-Born 10/23/20 11:13 AM               28\n5 First-Born 10/23/20 3:49 PM                14\n6 First-Born 10/23/20 7:16 PM               298\n\n\nHmmm, okay. So a few issues to deal with:\n\nthe Time column is character data, instead of POSIXct\nyou have durations, instead of start times and end times\n\nWhat I would love is a graph of my son’s sleep schedule, by week, that I could match up with our second child. So let’s see what we can do.\n\n\nThe first thing to do is make sure that the data is in time. R has many functions, which you adapt to the way that the data looks. Here, the data is in month/day/year hour:minutes, so we can use mdy_hm as the function.\n\n\nCode in R\nchild &lt;- child |&gt; \n  mutate(starttime=mdy_hm(Time)) |&gt; \n  select(-Time)\n   \nhead(child)         \n\n\n# A tibble: 6 × 3\n  Baby       `Duration (min)` starttime          \n  &lt;chr&gt;                 &lt;dbl&gt; &lt;dttm&gt;             \n1 First-Born               60 2020-10-23 04:30:00\n2 First-Born               55 2020-10-23 06:00:00\n3 First-Born               39 2020-10-23 08:31:00\n4 First-Born               28 2020-10-23 11:13:00\n5 First-Born               14 2020-10-23 15:49:00\n6 First-Born              298 2020-10-23 19:16:00\n\n\nWe can similarly convert the Duration to minutes and add it to the starttime to get an endtime using the minutes function\n\n\nCode in R\nchild &lt;- child |&gt; \n  mutate(endtime=starttime+minutes(`Duration (min)`)) |&gt; \n  select(-`Duration (min)`)\n\n\nhead(child)\n\n\n# A tibble: 6 × 3\n  Baby       starttime           endtime            \n  &lt;chr&gt;      &lt;dttm&gt;              &lt;dttm&gt;             \n1 First-Born 2020-10-23 04:30:00 2020-10-23 05:30:00\n2 First-Born 2020-10-23 06:00:00 2020-10-23 06:55:00\n3 First-Born 2020-10-23 08:31:00 2020-10-23 09:10:00\n4 First-Born 2020-10-23 11:13:00 2020-10-23 11:41:00\n5 First-Born 2020-10-23 15:49:00 2020-10-23 16:03:00\n6 First-Born 2020-10-23 19:16:00 2020-10-24 00:14:00\n\n\n\n\n\nFor the graph I’m imagining, where rectangles on a plot where show the time sleeping, my son sleeping through the night will actually be two rectangles; one that goes in the evening until midnight, and then one the following day from midnight until he wakes up.\nThis show up in the dataset as ones where the day of starttime and endtime are different.\n\n\nCode in R\nchildnight &lt;- child |&gt; \n  filter(day(starttime) != day(endtime))\n\n## now make these into two different datasets. The evening dataset and the morning dataset\n\nchildevening &lt;- childnight |&gt; \n  mutate(endtime=\n           make_datetime(year(starttime), month(starttime), day(starttime), hour=23, min=59, sec=59))\n\nchildmorning &lt;- childnight |&gt; \n  mutate(starttime=\n           make_datetime(year(endtime), month(endtime), day(endtime), hour=0, min=0, sec=0))\n\n## now filter them out and bind back in\nchild &lt;- child |&gt; \n  filter(day(starttime) == day(endtime)) |&gt; \n  bind_rows(childevening,childmorning)\n\n\nNow we have a dataset! Next problem.\n\n\n\nBecause my two sons were not born on the same day (or even the same month), looking at the data by date is not going to be helpful; ideally, I want to look at it in how many weeks old they are.\n\n\nCode in R\nbirth &lt;- mdy(\"05-30-20\")\n\n\nUsing this birthdate, I can find the difference in time between the times sleeping and his birth. Using the floor function is akin to rounding down, which will allow me to see how many weeks old the baby was when sleep occurred.\nIdeally, I want these dates converted into what week old, and what day of that week, factored for a plot that goes from midnight to midnight. My son was born on a Sunday, so this can go from Sunday to Saturday.\n\n\nCode in R\nchild &lt;- child |&gt; \n  mutate( ## this tells you how many weeks old\n    weeksold=floor(difftime(starttime, birth, units=\"weeks\")),\n          ## this translates the dates into days of the week\n    dayweek=wday(starttime,label=TRUE, ##labels over numbers,\n                 abbr=TRUE, ##abbreviated,\n                 week_start=7 ## Sunday\n                 ),\n    starthour=hm(paste0(hour(starttime),\":\",minute(starttime))),\n    endhour=hm(paste0(hour(endtime),\":\",minute(endtime)))) |&gt; \n  select(-c(starttime,endtime))\n\nhead(child)\n\n\n# A tibble: 6 × 5\n  Baby       weeksold dayweek starthour  endhour   \n  &lt;chr&gt;      &lt;drtn&gt;   &lt;ord&gt;   &lt;Period&gt;   &lt;Period&gt;  \n1 First-Born 20 weeks Fri     4H 30M 0S  5H 30M 0S \n2 First-Born 20 weeks Fri     6H 0M 0S   6H 55M 0S \n3 First-Born 20 weeks Fri     8H 31M 0S  9H 10M 0S \n4 First-Born 20 weeks Fri     11H 13M 0S 11H 41M 0S\n5 First-Born 20 weeks Fri     15H 49M 0S 16H 3M 0S \n6 First-Born 21 weeks Sat     49M 0S     7H 20M 0S \n\n\nNow we are ready to graph!\n\n\n\ngeom_rect does not work well with categorical data, so we will use the fact that factors have numerical orders underneath them to graph.\nThis creates a funny first graph.\n\n\nCode in R\nchild |&gt; \n  filter(weeksold %in% c(21:29)) |&gt; \n  ggplot() +\n  geom_rect(mapping=aes(xmin=as.numeric(dayweek)-.45,\n                        xmax=as.numeric(dayweek)+.45,\n                        ymin=starthour,\n                        ymax=endhour),\n            fill=\"blue\", alpha=.5) +\n  facet_wrap(~weeksold)\n\n\n\n\n\nA plot with numbers on each side…\n\n\n\n\nNotice that the y axis is in seconds since midnight, and that the x axis is in days since Sunday. Let’s work with our scales to make these right\n\n\nCode in R\nBREAKS &lt;- c(0:12) * 7200 ## there are 3600 seconds in an hour, so this should make breaks every 2 hours\n\nchild |&gt; \n  filter(weeksold %in% c(21:29)) |&gt; \n  ggplot() +\n  geom_rect(mapping=aes(xmin=as.numeric(dayweek)-.45,\n                        xmax=as.numeric(dayweek)+.45,\n                        ymin=starthour,\n                        ymax=endhour),\n            fill=\"blue\", alpha=.5) +\n  facet_wrap(~weeksold) +\n  scale_y_time(breaks=BREAKS) +\n  scale_x_continuous(\n    breaks=seq_along(levels(child$dayweek)),\n    labels=levels(child$dayweek)\n  ) +\n  labs(title=\"Sleep Schedule by Weeks Old, Weeks 21-29\") +\n  theme_light()\n\n\n\n\n\nA final plot\n\n\n\n\nA graph to be proud of, and a reminder that my first son was a far better sleeper at night than my current…"
  },
  {
    "objectID": "posts/2025-02-04-plotting-sleep-intervals/index.html#creating-a-tidy-time-dataframe",
    "href": "posts/2025-02-04-plotting-sleep-intervals/index.html#creating-a-tidy-time-dataframe",
    "title": "Working with Time to battle Baby Amnesia",
    "section": "",
    "text": "The first thing to do is make sure that the data is in time. R has many functions, which you adapt to the way that the data looks. Here, the data is in month/day/year hour:minutes, so we can use mdy_hm as the function.\n\n\nCode in R\nchild &lt;- child |&gt; \n  mutate(starttime=mdy_hm(Time)) |&gt; \n  select(-Time)\n   \nhead(child)         \n\n\n# A tibble: 6 × 3\n  Baby       `Duration (min)` starttime          \n  &lt;chr&gt;                 &lt;dbl&gt; &lt;dttm&gt;             \n1 First-Born               60 2020-10-23 04:30:00\n2 First-Born               55 2020-10-23 06:00:00\n3 First-Born               39 2020-10-23 08:31:00\n4 First-Born               28 2020-10-23 11:13:00\n5 First-Born               14 2020-10-23 15:49:00\n6 First-Born              298 2020-10-23 19:16:00\n\n\nWe can similarly convert the Duration to minutes and add it to the starttime to get an endtime using the minutes function\n\n\nCode in R\nchild &lt;- child |&gt; \n  mutate(endtime=starttime+minutes(`Duration (min)`)) |&gt; \n  select(-`Duration (min)`)\n\n\nhead(child)\n\n\n# A tibble: 6 × 3\n  Baby       starttime           endtime            \n  &lt;chr&gt;      &lt;dttm&gt;              &lt;dttm&gt;             \n1 First-Born 2020-10-23 04:30:00 2020-10-23 05:30:00\n2 First-Born 2020-10-23 06:00:00 2020-10-23 06:55:00\n3 First-Born 2020-10-23 08:31:00 2020-10-23 09:10:00\n4 First-Born 2020-10-23 11:13:00 2020-10-23 11:41:00\n5 First-Born 2020-10-23 15:49:00 2020-10-23 16:03:00\n6 First-Born 2020-10-23 19:16:00 2020-10-24 00:14:00"
  },
  {
    "objectID": "posts/2025-02-04-plotting-sleep-intervals/index.html#separating-out-sleep-at-night",
    "href": "posts/2025-02-04-plotting-sleep-intervals/index.html#separating-out-sleep-at-night",
    "title": "Working with Time to battle Baby Amnesia",
    "section": "",
    "text": "For the graph I’m imagining, where rectangles on a plot where show the time sleeping, my son sleeping through the night will actually be two rectangles; one that goes in the evening until midnight, and then one the following day from midnight until he wakes up.\nThis show up in the dataset as ones where the day of starttime and endtime are different.\n\n\nCode in R\nchildnight &lt;- child |&gt; \n  filter(day(starttime) != day(endtime))\n\n## now make these into two different datasets. The evening dataset and the morning dataset\n\nchildevening &lt;- childnight |&gt; \n  mutate(endtime=\n           make_datetime(year(starttime), month(starttime), day(starttime), hour=23, min=59, sec=59))\n\nchildmorning &lt;- childnight |&gt; \n  mutate(starttime=\n           make_datetime(year(endtime), month(endtime), day(endtime), hour=0, min=0, sec=0))\n\n## now filter them out and bind back in\nchild &lt;- child |&gt; \n  filter(day(starttime) == day(endtime)) |&gt; \n  bind_rows(childevening,childmorning)\n\n\nNow we have a dataset! Next problem."
  },
  {
    "objectID": "posts/2025-02-04-plotting-sleep-intervals/index.html#translating-data-into-weeks-old",
    "href": "posts/2025-02-04-plotting-sleep-intervals/index.html#translating-data-into-weeks-old",
    "title": "Working with Time to battle Baby Amnesia",
    "section": "",
    "text": "Because my two sons were not born on the same day (or even the same month), looking at the data by date is not going to be helpful; ideally, I want to look at it in how many weeks old they are.\n\n\nCode in R\nbirth &lt;- mdy(\"05-30-20\")\n\n\nUsing this birthdate, I can find the difference in time between the times sleeping and his birth. Using the floor function is akin to rounding down, which will allow me to see how many weeks old the baby was when sleep occurred.\nIdeally, I want these dates converted into what week old, and what day of that week, factored for a plot that goes from midnight to midnight. My son was born on a Sunday, so this can go from Sunday to Saturday.\n\n\nCode in R\nchild &lt;- child |&gt; \n  mutate( ## this tells you how many weeks old\n    weeksold=floor(difftime(starttime, birth, units=\"weeks\")),\n          ## this translates the dates into days of the week\n    dayweek=wday(starttime,label=TRUE, ##labels over numbers,\n                 abbr=TRUE, ##abbreviated,\n                 week_start=7 ## Sunday\n                 ),\n    starthour=hm(paste0(hour(starttime),\":\",minute(starttime))),\n    endhour=hm(paste0(hour(endtime),\":\",minute(endtime)))) |&gt; \n  select(-c(starttime,endtime))\n\nhead(child)\n\n\n# A tibble: 6 × 5\n  Baby       weeksold dayweek starthour  endhour   \n  &lt;chr&gt;      &lt;drtn&gt;   &lt;ord&gt;   &lt;Period&gt;   &lt;Period&gt;  \n1 First-Born 20 weeks Fri     4H 30M 0S  5H 30M 0S \n2 First-Born 20 weeks Fri     6H 0M 0S   6H 55M 0S \n3 First-Born 20 weeks Fri     8H 31M 0S  9H 10M 0S \n4 First-Born 20 weeks Fri     11H 13M 0S 11H 41M 0S\n5 First-Born 20 weeks Fri     15H 49M 0S 16H 3M 0S \n6 First-Born 21 weeks Sat     49M 0S     7H 20M 0S \n\n\nNow we are ready to graph!"
  },
  {
    "objectID": "posts/2025-02-04-plotting-sleep-intervals/index.html#graphing",
    "href": "posts/2025-02-04-plotting-sleep-intervals/index.html#graphing",
    "title": "Working with Time to battle Baby Amnesia",
    "section": "",
    "text": "geom_rect does not work well with categorical data, so we will use the fact that factors have numerical orders underneath them to graph.\nThis creates a funny first graph.\n\n\nCode in R\nchild |&gt; \n  filter(weeksold %in% c(21:29)) |&gt; \n  ggplot() +\n  geom_rect(mapping=aes(xmin=as.numeric(dayweek)-.45,\n                        xmax=as.numeric(dayweek)+.45,\n                        ymin=starthour,\n                        ymax=endhour),\n            fill=\"blue\", alpha=.5) +\n  facet_wrap(~weeksold)\n\n\n\n\n\nA plot with numbers on each side…\n\n\n\n\nNotice that the y axis is in seconds since midnight, and that the x axis is in days since Sunday. Let’s work with our scales to make these right\n\n\nCode in R\nBREAKS &lt;- c(0:12) * 7200 ## there are 3600 seconds in an hour, so this should make breaks every 2 hours\n\nchild |&gt; \n  filter(weeksold %in% c(21:29)) |&gt; \n  ggplot() +\n  geom_rect(mapping=aes(xmin=as.numeric(dayweek)-.45,\n                        xmax=as.numeric(dayweek)+.45,\n                        ymin=starthour,\n                        ymax=endhour),\n            fill=\"blue\", alpha=.5) +\n  facet_wrap(~weeksold) +\n  scale_y_time(breaks=BREAKS) +\n  scale_x_continuous(\n    breaks=seq_along(levels(child$dayweek)),\n    labels=levels(child$dayweek)\n  ) +\n  labs(title=\"Sleep Schedule by Weeks Old, Weeks 21-29\") +\n  theme_light()\n\n\n\n\n\nA final plot\n\n\n\n\nA graph to be proud of, and a reminder that my first son was a far better sleeper at night than my current…"
  },
  {
    "objectID": "posts/2025-03-02-hertzsprung-russell/index.html",
    "href": "posts/2025-03-02-hertzsprung-russell/index.html",
    "title": "Constructing the Hertzsprung-Russell Diagram",
    "section": "",
    "text": "For a few Fridays each year, I teach a course in the American Museum of Natural History’s Masters of Arts in Teaching program to apply and continue thinking about my work as an Earth Science teacher and a teacher educator. In this course, I co-teach a course of Space Systems with an astrophysicist at the musem. For the last few years, this has been with the incredible Dr. Jackie Faherty, a museum educator and astrophysicist whose work focuses on the fields of brown dwarfs and exoplanets.\nA couple of years ago, the museum received a grant to embed computational thinking in our science education courses. After many discussions around what we believe computational thinking to actually mean, Jackie brought up glue, a Python-based app designed for easy exploratory visualizations of large datasets. Thus, she designed a set of exercises that allows students to explore exoplanet databases to understand the differences between exoplanet systems and our own, and touching upon topics such as bias in measurement, calculations of a variable through an easy to approach GUI-interface.\nThis year, I recreated the exercises in R. My favorite is on recreating the Hertzsprung-Russell diagram. In class, they recreate it using an exoplanet database, but below, we recreate using a slightly larger catalog of stars that includes stars that we haven’t yet found exoplanets around.\n\n\nThe dataset is a bit large, so I’m afraid you will need to download it yourself. I used the latest version of the HYG (Hipparcos, Yale, Gliese) Stellar database, as kept here. In glancing at the data, it looks like stars have a maximum distance that is creating a lot of outliers, so if you are recreating your graph using this dataset, please use the same filter in my code (I also filtered out variable stars, as they don’t have a set luminosity).\nNow let’s graph it. The easiest way to plot an H-R diagram is with the color index, which is also related to surface temperature and spectral type, on the x-axis and the luminosity, which is also related to absolute magnitude1 on the y axis.\n\n\nCode in R\nlibrary(tidyverse)\n# let's not work in scientific notation unless we specify it\noptions(scipen = 999)\n \nstars &lt;- read_csv(\"data/hygdata_v41.csv\") |&gt; \n    filter(dist &lt; 100000,\n           is.na(var))\n\np &lt;-stars |&gt; \n  ggplot(aes(x=ci, y=lum)) +\n  geom_point(size=0.02) +\n  scale_y_log10() +\n  theme_bw()\n\np\n\n\n\n\n\nThat looks a bit like an H-R diagram\n\n\n\n\nI want to use histograms to figure out where the limits of this should be and to get a sense of the distribution. To do that, I will use the excellent ggExtra package, where you can add in marginal plots.\n\n\nCode in R\nlibrary(ggExtra)\n\nggMarginal(p,\n  type=\"histogram\"\n)\n\n\n\n\n\n\n\n\n\nThe y-axis looks to be pretty good, but the x axis could probably shrink to a color index with a maximum of 3.\n\n\n\nMost H-R diagram plots hint at the color of the stars, which we should be able to do as well. Let’s try it out with scale_color_gradient2, which is designed for divergent palettes, from RColorBrewer.\n\n\nCode in R\nlibrary(RColorBrewer)\n\nstars |&gt; \n  ggplot(aes(x=ci, y=lum,color=ci)) +\n  geom_point(size=0.02, show.legend=FALSE) +\n  scale_y_log10() +\n  scale_x_continuous(limits=c(-.5,2.25))+\n  scale_color_gradient2(low= \"blue\", mid=\"white\", high=\"red\",midpoint=0.75) +\n  theme_minimal() +\n  theme(panel.background=element_rect(fill=\"black\"),\n        panel.grid=element_blank()) +\n  labs(title=\"Hertzsprung-Russell Diagram\",\n       y=\"Luminosity (in comparison to Sun)\",\n       x=\"Color Index (blue magnitude - visual magnitude)\")"
  },
  {
    "objectID": "posts/2025-03-02-hertzsprung-russell/index.html#loading-the-data-and-finding-the-right-margins",
    "href": "posts/2025-03-02-hertzsprung-russell/index.html#loading-the-data-and-finding-the-right-margins",
    "title": "Constructing the Hertzsprung-Russell Diagram",
    "section": "",
    "text": "The dataset is a bit large, so I’m afraid you will need to download it yourself. I used the latest version of the HYG (Hipparcos, Yale, Gliese) Stellar database, as kept here. In glancing at the data, it looks like stars have a maximum distance that is creating a lot of outliers, so if you are recreating your graph using this dataset, please use the same filter in my code (I also filtered out variable stars, as they don’t have a set luminosity).\nNow let’s graph it. The easiest way to plot an H-R diagram is with the color index, which is also related to surface temperature and spectral type, on the x-axis and the luminosity, which is also related to absolute magnitude1 on the y axis.\n\n\nCode in R\nlibrary(tidyverse)\n# let's not work in scientific notation unless we specify it\noptions(scipen = 999)\n \nstars &lt;- read_csv(\"data/hygdata_v41.csv\") |&gt; \n    filter(dist &lt; 100000,\n           is.na(var))\n\np &lt;-stars |&gt; \n  ggplot(aes(x=ci, y=lum)) +\n  geom_point(size=0.02) +\n  scale_y_log10() +\n  theme_bw()\n\np\n\n\n\n\n\nThat looks a bit like an H-R diagram\n\n\n\n\nI want to use histograms to figure out where the limits of this should be and to get a sense of the distribution. To do that, I will use the excellent ggExtra package, where you can add in marginal plots.\n\n\nCode in R\nlibrary(ggExtra)\n\nggMarginal(p,\n  type=\"histogram\"\n)\n\n\n\n\n\n\n\n\n\nThe y-axis looks to be pretty good, but the x axis could probably shrink to a color index with a maximum of 3."
  },
  {
    "objectID": "posts/2025-03-02-hertzsprung-russell/index.html#getting-some-color-into-this-plot",
    "href": "posts/2025-03-02-hertzsprung-russell/index.html#getting-some-color-into-this-plot",
    "title": "Constructing the Hertzsprung-Russell Diagram",
    "section": "",
    "text": "Most H-R diagram plots hint at the color of the stars, which we should be able to do as well. Let’s try it out with scale_color_gradient2, which is designed for divergent palettes, from RColorBrewer.\n\n\nCode in R\nlibrary(RColorBrewer)\n\nstars |&gt; \n  ggplot(aes(x=ci, y=lum,color=ci)) +\n  geom_point(size=0.02, show.legend=FALSE) +\n  scale_y_log10() +\n  scale_x_continuous(limits=c(-.5,2.25))+\n  scale_color_gradient2(low= \"blue\", mid=\"white\", high=\"red\",midpoint=0.75) +\n  theme_minimal() +\n  theme(panel.background=element_rect(fill=\"black\"),\n        panel.grid=element_blank()) +\n  labs(title=\"Hertzsprung-Russell Diagram\",\n       y=\"Luminosity (in comparison to Sun)\",\n       x=\"Color Index (blue magnitude - visual magnitude)\")"
  },
  {
    "objectID": "posts/2025-03-02-hertzsprung-russell/index.html#footnotes",
    "href": "posts/2025-03-02-hertzsprung-russell/index.html#footnotes",
    "title": "Constructing the Hertzsprung-Russell Diagram",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf you are plotting absolute magnitude, remember to add in scale_y_reverse, as brighter stars have a lower magnitude.↩︎"
  },
  {
    "objectID": "posts/2025-04-12-Plotly-Pollen-Dataset/index.html",
    "href": "posts/2025-04-12-Plotly-Pollen-Dataset/index.html",
    "title": "Exploring a 3-D Synthetic Dataset",
    "section": "",
    "text": "Exploring the HistData package\nOver on BlueSky, I have been working through a few challenges. For the months of February and March, I participated in the DuBois Challenge, where you take a week to recreate some of the powerful visualizations that came out of the Paris Exposition from W.E.B. Du Bois. My work there, complete with code, can be found in my github\nInspired by this, I’ve also been doing the #30DayChartChallenge, where you make a chart a day on a theme that changes each day. I have taken this as an opportunity to explore Michael Friendly’s HistData package, which draws from his excellent book with Howard Wainer. I have done posts on John Snow, the Trial of the Pyx, Florence Nightingale, and others on my github. However, one dataset that a simple plot doesn’t do justice to is the Pollen dataset. This dataset, like mtcars and flights, are synthetic datasets that were used as data challenges (the other two are now basic datasets for reprexes as well).\nThis dataset, however, shows the power of plotly.\n\n\nCode in R\nlibrary(tidyverse)\nlibrary(HistData)\nlibrary(plotly)\n\ndata(\"Pollen\")\nhead(Pollen)\n\n\n# A tibble: 6 × 5\n  ridge   nub crack  weight density\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 -2.35  3.63  5.03  10.9     -1.39\n2 -1.15  1.48  3.24  -0.594    2.12\n3 -2.52 -6.86 -2.80   8.46    -3.41\n4  5.75 -6.51 -5.15   4.35   -10.3 \n5  8.75 -3.90 -1.38 -14.9     -2.42\n6 10.4  -3.16 12.8  -14.9     -6.49\n\n\nThe first three variables are meant to be plotted on the x, y and z axis, where the other variables are meant to describe the grains of pollen. Doing a quick correlation shows that there is at least one strong correlation that can be seen through the use of color, where weight is highly correlated with the x-axis.\n\n\nCode in R\nres &lt;- cor(Pollen)\nround(res,2)\n\n\n        ridge   nub crack weight density\nridge    1.00  0.13 -0.13  -0.90   -0.57\nnub      0.13  1.00  0.08  -0.17    0.33\ncrack   -0.13  0.08  1.00   0.27   -0.15\nweight  -0.90 -0.17  0.27   1.00    0.24\ndensity -0.57  0.33 -0.15   0.24    1.00\n\n\nHowever, when you plot the dataset, something else shows up. Thankfully, plotly allows you to drag a plot around to explore it.\n\n\nCode in R\nplot_ly(Pollen, x = ~ridge, y = ~nub, z = ~crack)  |&gt; \n  add_markers(color = ~weight, size=2) |&gt; \n  layout(title=\"David Coleman's Synthetic Pollen Dataset\")|&gt;\n  config(displayModeBar=FALSE)\n\n\n\n\n\n\nCan you see it? Image below to recreate…\n\n\n\nEureka!\n\n\n\n\n\n\nCitationBibTeX citation:@online{russell2025,\n  author = {Russell, John},\n  title = {Exploring a {3-D} {Synthetic} {Dataset}},\n  date = {2025-04-12},\n  url = {https://drjohnrussell.github.io/posts/2025-04-12-Plotly-Pollen-Dataset/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nRussell, John. 2025. “Exploring a 3-D Synthetic Dataset.”\nApril 12, 2025. https://drjohnrussell.github.io/posts/2025-04-12-Plotly-Pollen-Dataset/."
  }
]